{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated uploading into a PostgreSQL database\n",
    "Automatically detect and upload new CSV files placed in a specific directory to a PostgreSQL server, using a combination of shell scripting and a loop to continuously monitor the directory for new files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use\n",
    "\n",
    "1. Open a text editor and create a new file.\n",
    "  \n",
    "2. Copy and paste the script into the file.\n",
    "  \n",
    "3. Replace the placeholder values with your actual database connection details, directory paths, and any other necessary configurations. Make sure to update the following variables:\n",
    "  \n",
    "   - `DB_HOST`: Replace with the hostname or IP address of your PostgreSQL database server.\n",
    "   - `DB_PORT`: Replace with the port number of your PostgreSQL database server.\n",
    "   - `DB_NAME`: Replace with the name of your PostgreSQL database.\n",
    "   - `DB_USER`: Replace with the username to connect to your PostgreSQL database.\n",
    "   - `DB_PASSWORD`: Replace with the password to connect to your PostgreSQL database.\n",
    "   - `DIRECTORY`: Replace with the path to the directory where your CSV files are located.\n",
    "   - `TABLE_NAME`: Replace with the desired name for the table in which the CSV data will be loaded.\n",
    "  \n",
    "4. Save the file with a `.sh` extension, for example, `csv_loader.sh`.\n",
    "  \n",
    "5. Open a terminal or command prompt.\n",
    "  \n",
    "6. Navigate to the directory where the script file is located using the `cd` command.\n",
    "  \n",
    "7. Make the script file executable by running the following command:  \n",
    "   `chmod +x csv_loader.sh`\n",
    "  \n",
    "8. Run the script by executing the following command:  \n",
    "   `./csv_loader.sh`\n",
    "  \n",
    "9. The script will start monitoring the specified directory for new CSV files. Whenever a new CSV file is detected, it will be loaded into the PostgreSQL database as a new table, and the file information will be logged in the `processed_files.txt` file.\n",
    "  \n",
    "10. The script will continue running in the background, checking for new files every 5 seconds. You can leave it running, and it will automatically process any new CSV files placed in the directory.\n",
    "  \n",
    "Remember to have PostgreSQL and the necessary dependencies installed on your system for the script to work properly.\n",
    "  \n",
    "NOTE: If you encounter any permission issues or errors, make sure you have the necessary permissions to access the files and directories, and check that the database connection details are correct.  \n",
    "Make sure to give execute permissions to the script using **chmod +x script.sh**, where script.sh is the name of your shell script file. Then, you can run the script using ./script.sh to start monitoring the directory and automatically upload new CSV files to PostgreSQL."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To run the script continuously in the background, you have a couple of options:\n",
    "  \n",
    "1. **Using nohup: You can run the script with `nohup` to detach it from the terminal and keep it running in the background. The script will continue running even after you close the terminal session.**  \n",
    "\n",
    "- Here's an example: `nohup ./script.sh &`  \n",
    "- The & at the end is used to run the script in the background. The script's output will be redirected to a file named nohup.out.  \n",
    "  \n",
    "<br><br>\n",
    "2. **Using screen: Another option is to use the screen utility, which allows you to create a virtual terminal session that continues running even after you disconnect from it. Here's how you can use it**:  \n",
    "  \n",
    "- Start a new screen session: `screen -S mysession`\n",
    "- Run the script in the screen session: `./script.sh`\n",
    "- Detach from the screen session: Press `Ctrl+A` followed by `d`\n",
    "  \n",
    "The script will keep running within the screen session even if you close the terminal or disconnect from the SSH session. You can later reattach to the screen session using screen `-r mysession`.  \n",
    "  \n",
    "<br><br>\n",
    "3. **Using crontab: The cron command-line utility is a job scheduler on Unix-like operating systems. Users who set up and maintain software environments use cron to schedule jobs, also known as cron jobs, to run periodically at fixed times, dates, or intervals.**  \n",
    "  \n",
    "- Open the terminal and run the following command to open the crontab editor: `crontab -e`\n",
    "- If prompted to select an editor, choose your preferred text editor (e.g., nano, vim).\n",
    "- In the crontab file, each line represents a scheduled task. Each task is defined by a cron expression followed by the command to be executed.\n",
    "- Add a new line to the crontab file with the schedule and command to run your script. For example, to run the script every 5 minutes, you can use the following line: `*/5 * * * * /path/to/your/script.sh`  \n",
    "- - The */5 in the minute field means every 5 minutes.\n",
    "- - The * in the other fields means any value.\n",
    "- Save the crontab file and exit the editor.  \n",
    "  \n",
    "The script will now be executed automatically based on the specified schedule. Make sure the script has executable permissions via `chmod +x script.sh`  \n",
    "\n",
    "You can check the list of scheduled tasks by running `crontab -l` in the terminal.  \n",
    "  \n",
    "<br><br>\n",
    "NOTE: When using cron, make sure the environment variables and paths required by your script are properly set, as cron runs the tasks in a different environment than your interactive shell.  \n",
    "  \n",
    "NOTE: Both `nohup` and `screen` options allow you to keep the script running in the background. You don't need to use `crontab` in this case unless you specifically want to schedule the script to run at specific intervals.\n",
    "\n",
    "---\n",
    "## What if I am running it on my personal computer?\n",
    "**nohup**: When you shut down your computer, the nohup-launched script will be terminated. It is not designed to survive a system shutdown. If you want the script to continue running even after your computer is shut down, you would need to consider other options.  \n",
    "  \n",
    "**screen**: The session remains active even if you shut down your computer. When you power on your computer again, you can reconnect to the screen session using the screen -r command. The script within the screen session will resume its execution as if it was never interrupted.  \n",
    "Using screen allows you to detach and reattach to the session, which makes it suitable for long-running tasks that need to persist even when the computer is offline. However, please note that screen will only keep the session alive if the underlying system remains running. If the system itself is shut down, the screen session will be terminated.  \n",
    "  \n",
    "**crontab**: If you shut down your computer, the scheduled tasks in cron will not run until your computer is powered on again. cron relies on the operating system being up and running to execute the scheduled tasks.  \n",
    "  \n",
    "<br><br>\n",
    "To automatically run a script when you power on your computer, you can add a startup script or configure a system service depending on your operating system.  \n",
    "1. Linux (`systemd`): If you are using a Linux distribution with systemd as the init system (e.g., Ubuntu, CentOS), you can create a systemd service to run your script at startup.  \n",
    "Here's a general outline of the steps:  \n",
    "- Create a service unit file for your script. Open a text editor and create a file, for example, myscript.service, in the `/etc/systemd/system/` directory with the following content:\n",
    "```\n",
    "[Unit]\n",
    "Description=My Script\n",
    "After=network.target\n",
    "\n",
    "[Service]\n",
    "ExecStart=/path/to/your/script.sh\n",
    "\n",
    "[Install]\n",
    "WantedBy=default.target\n",
    "```\n",
    "- Save the file and exit the text editor.\n",
    "- Enable and start the service using the following commands:\n",
    "```\n",
    "sudo systemctl enable myscript.service\n",
    "sudo systemctl start myscript.service\n",
    "```\n",
    "- Now, the script will be executed automatically each time the system starts up.  \n",
    "  \n",
    "\n",
    "2. macOS (`LaunchAgents`): On macOS, you can use LaunchAgents to run a script at login. Here's a general outline of the steps:  \n",
    "- Create a property list (plist) file for the script. Open a text editor and create a file, for example, `com.example.myscript.plist`, in the `~/Library/LaunchAgents/` directory with the following content:  \n",
    "```\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n",
    "<plist version=\"1.0\">\n",
    "<dict>\n",
    "  <key>Label</key>\n",
    "  <string>com.example.myscript</string>\n",
    "  <key>ProgramArguments</key>\n",
    "  <array>\n",
    "    <string>/path/to/your/script.sh</string>\n",
    "  </array>\n",
    "  <key>RunAtLoad</key>\n",
    "  <true/>\n",
    "</dict>\n",
    "</plist>\n",
    "```\n",
    "- Save the file and exit the text editor.\n",
    "- Load the LaunchAgent using the following command:  \n",
    "`launchctl load ~/Library/LaunchAgents/com.example.myscript.plist`\n",
    "- Now, your script will be executed automatically each time you log in to your macOS system.\n",
    "  \n",
    "NOTE: Process may vary slightly depending on OS.\n",
    "  \n",
    "---\n",
    "## Where should I place the script?\n",
    "The placement of the script depends on your specific requirements and system configuration. \n",
    "Here are a few options to consider:\n",
    "\n",
    "**User's home directory**: You can place the script in your user's home directory. This allows you to easily access and modify the script. You can create a new directory, such as scripts, within your home directory and place the script file there.  \n",
    "Example: `/home/your_username/scripts/script.sh`\n",
    "  \n",
    "**System-wide location**: If you want the script to be available for all users on the system, you can place it in a system-wide location, such as /usr/local/bin or /opt. This requires administrative privileges.  \n",
    "Example: `/usr/local/bin/script.sh`\n",
    "  \n",
    "**Custom directory**: You can create a custom directory specifically for your scripts and place the script file there. This can be useful if you have multiple scripts and want to keep them organized in a single location.  \n",
    "Example: `/path/to/your/scripts/script.sh`\n",
    "  \n",
    "<br><br>\n",
    "Once you have decided on the location, make sure the script file has executable permissions so that it can be run.  \n",
    "You can set the permissions using the chmod command: `chmod +x /path/to/your/scripts/script.sh`\n",
    "  \n",
    "After placing the script in the desired location, you can run it using the command: `./script.sh` (assuming you are in the same directory) or by specifying the full path to the script file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of each part\n",
    "The script will continue running indefinitely, periodically checking the specified directory for new CSV files, processing them, and marking them as processed to avoid duplicate processing. \n",
    "  \n",
    "Here is a breakdown:\n",
    "  \n",
    "1. `#!/bin/bash`: This is called the shebang and specifies the interpreter to be used, in this case, /bin/bash. It indicates that the script should be executed using the Bash shell.\n",
    "  \n",
    "2. `DB_HOST, DB_PORT, DB_NAME, DB_USER, DB_PASSWORD`: These variables store the connection details for the PostgreSQL database. You need to replace the placeholder values with your actual database connection information.\n",
    "  \n",
    "3. `DIRECTORY` and `PROCESSED_DIRECTORY`: These variables hold the path to the directories that will be monitored for CSV files. Replace the placeholder value with the actual path to the directory you want to monitor and the specified processed directory.\n",
    "  \n",
    "4. `process_csv_file()`: This is a function named process_csv_file that takes a CSV file path as an argument. It extracts the table name from the CSV file name by removing the file extension and replacing spaces with hyphens.\n",
    "  \n",
    "5. `header=$(head -n 1 \"$csv_file\")`: This retrieves the header of the CSV file using the head command, which contains the column names.\n",
    "  \n",
    "6. `column_names=$(echo \"$header\" | tr ',' '\\n' | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')`: It then uses echo, tr, and sed to convert the comma-separated column names into separate lines and remove leading/trailing spaces.\n",
    "  \n",
    "7. `create_table_sql=\"CREATE TABLE IF NOT EXISTS $table_name (${column_names[*]});\"`  \n",
    "`psql -h $DB_HOST -p $DB_PORT -d $DB_NAME -U $DB_USER -c \"$create_table_sql\"` : Creates a SQL statement to create a table in the database with the extracted table name and column names. The psql command executes the SQL statement using the provided database connection details.\n",
    "  \n",
    "8. `psql -h $DB_HOST -p $DB_PORT -d $DB_NAME -U $DB_USER -c \"\\\\copy $table_name FROM '$csv_file' DELIMITER ',' CSV HEADER\"` : executes the psql command to load the CSV file into the corresponding table in the database using the COPY command. The \\\\copy is used to perform the COPY operation from a local file, and the file path is provided.  \n",
    "  \n",
    "9. `mv \"$csv_file\" \"$PROCESSED_DIRECTORY\"`: This moves the processed CSV file to the specified processed directory using the mv command.\n",
    "  \n",
    "10. `processed_date=$(date +\"%Y-%m-%d %H:%M:%S\")`  \n",
    "`file_size=$(du -h \"$PROCESSED_DIRECTORY/${csv_file##*/}\" | awk '{print $1}')`  \n",
    "`echo \"$processed_date | File: ${csv_file##*/} | Size: $file_size\" >> processed_files.txt`: These lines obtain the current date and time using the date command and store it in the processed_date variable. The file size is obtained using the du command, and awk is used to extract the file size from the du output. The processed file information, including the date, file name, and file size, is then appended to the processed_files.txt log file.\n",
    "  \n",
    "11. `while true; do`: This starts an infinite loop using while true. The script will keep running until manually interrupted.\n",
    "  \n",
    "12. `csv_files=$(find \"$DIRECTORY\" -maxdepth 1 -type f -name \"*.csv\")`: This line uses the find command to search for CSV files (*.csv) in the specified directory ($DIRECTORY). The found file paths are stored in the csv_files variable.\n",
    "  \n",
    "13. `if [ -n \"$csv_files\" ]; then`: This checks if there are any CSV files found in the directory. The condition [ -n \"$csv_files\" ] checks if the csv_files variable is not empty.\n",
    "  \n",
    "14. `for csv_file in $csv_files; do`: This starts a loop to iterate over each CSV file found in the directory.\n",
    "\n",
    "15. `if ! grep -qF \"$csv_file\" processed_files.txt; then`: This condition checks if the current CSV file is not already present in the processed_files.txt log file. It uses the grep command with the -qF options to search for an exact match (-F) of the file path ($csv_file) in the log file without printing any output (-q).\n",
    "  \n",
    "16. `echo \"Processing file: $csv_file\"`  \n",
    "`process_csv_file \"$csv_file\"`  \n",
    "`echo \"$csv_file\" >> processed_files.txt`  \n",
    "`fi`: f the CSV file is not found in the log file, it indicates that the file is new and needs to be processed. The file path is echoed to the console, the process_csv_file function is called to process the file, and the file path is appended to the processed_files.txt log file.\n",
    "  \n",
    "17. `sleep 5`: After processing the CSV files in the current iteration, the script waits for 5 seconds using the sleep command before starting the next iteration of the loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# Database connection details\n",
    "DB_HOST=\"localhost\"\n",
    "DB_PORT=\"5432\"\n",
    "DB_NAME=\"analysis\"\n",
    "DB_USER=\"postgres\"\n",
    "DB_PASSWORD=\"admin\"\n",
    "\n",
    "# Directories\n",
    "DIRECTORY=\"/Users/alexandergursky/Local_Repository/projects/CSV2PostgreSQL/deposit\"\n",
    "PROCESSED_DIRECTORY=\"/Users/alexandergursky/Local_Repository/projects/CSV2PostgreSQL/processed\"\n",
    "\n",
    "# Function to process CSV file\n",
    "process_csv_file() {\n",
    "  local csv_file=\"$1\"\n",
    "  local table_name=\"${csv_file##*/}\"\n",
    "  table_name=\"${table_name%.*}\"\n",
    "  table_name=\"${table_name// /-}\"  # Replace spaces with hyphens\n",
    "\n",
    "  # Read the header of the CSV file to get the column names\n",
    "  header=$(head -n 1 \"$csv_file\")\n",
    "  IFS=, read -ra column_names <<< \"$header\"\n",
    "\n",
    "  # Create a new table based on the CSV file name with dynamic column names\n",
    "  create_table_sql=\"CREATE TABLE IF NOT EXISTS $table_name (id SERIAL PRIMARY KEY\"\n",
    "  for column_name in \"${column_names[@]}\"; do\n",
    "    create_table_sql+=\", \\\"$column_name\\\" TEXT\"\n",
    "  done\n",
    "  create_table_sql+=\");\"\n",
    "  psql -h $DB_HOST -p $DB_PORT -d $DB_NAME -U $DB_USER -c \"$create_table_sql\"\n",
    "\n",
    "  # Insert data row by row\n",
    "  tail -n +2 \"$csv_file\" | while IFS=, read -ra values; do\n",
    "    # Prepare column names and values for the INSERT statement\n",
    "    column_list=$(printf '\"%s\",' \"${column_names[@]}\")\n",
    "    column_list=\"${column_list%,}\"  # Remove trailing comma\n",
    "    value_list=$(printf \"'%s',\" \"${values[@]}\")\n",
    "    value_list=\"${value_list%,}\"  # Remove trailing comma\n",
    "\n",
    "    insert_sql=\"INSERT INTO $table_name ($column_list) VALUES ($value_list);\"\n",
    "    psql -h $DB_HOST -p $DB_PORT -d $DB_NAME -U $DB_USER -c \"$insert_sql\"\n",
    "  done\n",
    "\n",
    "  # Move the processed file to the processed directory\n",
    "  mv \"$csv_file\" \"$PROCESSED_DIRECTORY\"\n",
    "\n",
    "  # Log the processed file information\n",
    "  processed_date=$(date +\"%Y-%m-%d %H:%M:%S\")\n",
    "  file_size=$(du -h \"$PROCESSED_DIRECTORY/${csv_file##*/}\" | awk '{print $1}')\n",
    "  echo \"$processed_date | File: ${csv_file##*/} | Size: $file_size\" >> processed_files.txt\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Loop to continuously monitor the directory for new CSV files\n",
    "while true; do\n",
    "  # Check if there are any CSV files in the directory\n",
    "  csv_files=$(find \"$DIRECTORY\" -maxdepth 1 -type f -name \"*.csv\")\n",
    "\n",
    "  if [ -n \"$csv_files\" ]; then\n",
    "    for csv_file in $csv_files; do\n",
    "      # Process the CSV file if it has not been processed before\n",
    "      if ! grep -qF \"$csv_file\" processed_files.txt; then\n",
    "        echo \"Processing file: $csv_file\"\n",
    "        process_csv_file \"$csv_file\"\n",
    "        echo \"$csv_file\" >> processed_files.txt\n",
    "      else\n",
    "        echo \"Skipping processed file: $csv_file\"\n",
    "      fi\n",
    "    done\n",
    "  fi\n",
    "\n",
    "  # Wait for a specified time before checking again\n",
    "  sleep 5\n",
    "done\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "currently it does not do the last line in a file but it works overall"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
