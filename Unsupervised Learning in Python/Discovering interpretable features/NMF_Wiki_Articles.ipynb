{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-negative matrix factorization (NMF)\n",
    "\n",
    "# NMF stands for \"non-negative matrix factorization\". NMF, like PCA, is a dimension reduction technique. \n",
    "# In constract to PCA, however, NMF models are interpretable. \n",
    "# This means an NMF model is both easier to understand yourself, and much easier for you to explain to others. \n",
    "# However, NMF can not be applied to every dataset.\n",
    "# It is required that the sample features be \"non-negative\", so greater than or equal to 0.\n",
    "\n",
    "# pip3 install pandas\n",
    "# pip3 install scikit-learn\n",
    "# pip3 install scipy\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Loading df\n",
    "df = pd.read_csv('/Users/alexandergursky/Local_Repository/Datasets/Dataset_Package/Wikipedia articles/wikipedia-vectors.csv', index_col=0)\n",
    "\n",
    "# csr_matrix is a data type that remembers only the non-zero entries, this saves space.\n",
    "articles = csr_matrix(df.transpose())\n",
    "titles = list(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   0.   0.   0.44]\n",
      " [0.   0.   0.   0.   0.   0.57]\n",
      " [0.   0.   0.   0.   0.   0.4 ]\n",
      " [0.   0.   0.   0.   0.   0.38]\n",
      " [0.   0.   0.   0.   0.   0.49]\n",
      " [0.01 0.01 0.01 0.03 0.   0.33]\n",
      " [0.   0.   0.02 0.   0.01 0.36]\n",
      " [0.   0.   0.   0.   0.   0.49]\n",
      " [0.02 0.01 0.   0.02 0.03 0.48]\n",
      " [0.01 0.03 0.03 0.07 0.02 0.34]\n",
      " [0.   0.   0.53 0.   0.03 0.  ]\n",
      " [0.   0.   0.36 0.   0.   0.  ]\n",
      " [0.01 0.01 0.31 0.06 0.01 0.02]\n",
      " [0.   0.01 0.34 0.01 0.   0.  ]\n",
      " [0.   0.   0.43 0.   0.04 0.  ]\n",
      " [0.   0.   0.48 0.   0.   0.  ]\n",
      " [0.01 0.02 0.38 0.03 0.   0.01]\n",
      " [0.   0.   0.48 0.   0.   0.  ]\n",
      " [0.   0.01 0.55 0.   0.   0.  ]\n",
      " [0.   0.   0.47 0.   0.   0.  ]\n",
      " [0.   0.01 0.02 0.52 0.06 0.01]\n",
      " [0.   0.   0.   0.51 0.   0.  ]\n",
      " [0.   0.01 0.   0.42 0.   0.  ]\n",
      " [0.   0.   0.   0.44 0.   0.  ]\n",
      " [0.   0.   0.   0.5  0.   0.  ]\n",
      " [0.1  0.09 0.   0.38 0.   0.01]\n",
      " [0.   0.   0.   0.57 0.   0.01]\n",
      " [0.01 0.01 0.   0.47 0.   0.01]\n",
      " [0.   0.   0.   0.58 0.   0.  ]\n",
      " [0.   0.   0.   0.53 0.01 0.01]\n",
      " [0.   0.41 0.   0.   0.   0.  ]\n",
      " [0.   0.61 0.   0.01 0.   0.  ]\n",
      " [0.01 0.27 0.   0.02 0.01 0.  ]\n",
      " [0.   0.64 0.   0.   0.   0.  ]\n",
      " [0.   0.61 0.   0.   0.   0.  ]\n",
      " [0.   0.34 0.   0.   0.   0.  ]\n",
      " [0.01 0.32 0.02 0.   0.01 0.  ]\n",
      " [0.01 0.21 0.01 0.05 0.02 0.01]\n",
      " [0.01 0.47 0.   0.02 0.   0.  ]\n",
      " [0.   0.64 0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.48 0.  ]\n",
      " [0.   0.   0.   0.   0.49 0.  ]\n",
      " [0.   0.   0.   0.   0.38 0.01]\n",
      " [0.   0.   0.   0.01 0.54 0.  ]\n",
      " [0.   0.   0.01 0.   0.42 0.  ]\n",
      " [0.   0.   0.   0.   0.51 0.  ]\n",
      " [0.   0.   0.   0.   0.37 0.  ]\n",
      " [0.   0.   0.04 0.   0.23 0.  ]\n",
      " [0.01 0.   0.02 0.01 0.33 0.04]\n",
      " [0.   0.   0.   0.   0.42 0.  ]\n",
      " [0.31 0.   0.   0.   0.   0.  ]\n",
      " [0.37 0.   0.   0.   0.   0.  ]\n",
      " [0.4  0.03 0.   0.02 0.   0.02]\n",
      " [0.38 0.   0.   0.04 0.   0.01]\n",
      " [0.44 0.   0.   0.   0.   0.  ]\n",
      " [0.46 0.   0.   0.   0.   0.  ]\n",
      " [0.28 0.   0.   0.05 0.   0.02]\n",
      " [0.45 0.   0.   0.   0.01 0.  ]\n",
      " [0.29 0.01 0.01 0.01 0.19 0.01]\n",
      " [0.38 0.01 0.   0.1  0.01 0.  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandergursky/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    }
   ],
   "source": [
    "# Creating an NMF instance\n",
    "model = NMF(n_components=6)\n",
    "\n",
    "# Fitting the model to articles (our data)\n",
    "model.fit(articles)\n",
    "\n",
    "# Transform the articles to work with our model\n",
    "nmf_features = model.transform(articles)\n",
    "\n",
    "# Print the NMF features\n",
    "print(nmf_features.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.003845\n",
      "1    0.000000\n",
      "2    0.000000\n",
      "3    0.575712\n",
      "4    0.000000\n",
      "5    0.000000\n",
      "Name: Anne Hathaway, dtype: float64\n",
      "0    0.000000\n",
      "1    0.005601\n",
      "2    0.000000\n",
      "3    0.422381\n",
      "4    0.000000\n",
      "5    0.000000\n",
      "Name: Denzel Washington, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create prediction df\n",
    "article_pred_df = pd.DataFrame(nmf_features, index=titles)\n",
    "\n",
    "# Print the row for 'Anne Hathaway'\n",
    "print(article_pred_df.loc['Anne Hathaway'])\n",
    "\n",
    "# Print the row for 'Denzel Washington'\n",
    "print(article_pred_df.loc['Denzel Washington'])\n",
    "\n",
    "# NMF components represent topics\n",
    "# Looking at the output we can see that feature '3' which is really the 4th contains the highest value\n",
    "# As both of these are actors, this make sense. Feature 3 would be used to construct both articles. \n",
    "# NMF learns topics of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 13125)\n",
      "film       0.627875\n",
      "award      0.253131\n",
      "starred    0.245283\n",
      "role       0.211450\n",
      "actress    0.186397\n",
      "Name: 3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Getting the words\n",
    "words_df = pd.read_csv('/Users/alexandergursky/Local_Repository/Datasets/Dataset_Package/Wikipedia articles/wikipedia-vocabulary-utf8.txt',header=None)\n",
    "\n",
    "# Extracting first column, the values, then turning them into a list.\n",
    "words_ls = words_df.iloc[:,0].values.tolist()\n",
    "\n",
    "# Create a DataFrame: components_df\n",
    "components_df = pd.DataFrame(model.components_ , columns=words_ls)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(components_df.shape)\n",
    "\n",
    "# Select row 3: component\n",
    "component = components_df.iloc[3]\n",
    "\n",
    "# Print result of nlargest\n",
    "print(component.nlargest())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52d43516e08ba44a91236334f3ff506a57085b07359b42e8a57478a41bcad1ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
