{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles & Pipelines In PySpark\n",
    "  \n",
    "Finally you'll learn how to make your models more efficient. You'll find out how to use pipelines to make your code clearer and easier to maintain. Then you'll use cross-validation to better test your models and select good model parameters. Finally you'll dabble in two types of ensemble model.\n",
    "  \n",
    "```\n",
    "Welcome to\n",
    "      ____              __\n",
    "     / __/__  ___ _____/ /__\n",
    "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
    "   /__ / .__/\\_,_/_/ /_/\\_\\   \n",
    "      /_/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "  \n",
    "**Notebook Syntax**\n",
    "  \n",
    "<span style='color:#7393B3'>NOTE:</span>  \n",
    "- Denotes additional information deemed to be *contextually* important\n",
    "- Colored in blue, HEX #7393B3\n",
    "  \n",
    "<span style='color:#E74C3C'>WARNING:</span>  \n",
    "- Significant information that is *functionally* critical  \n",
    "- Colored in red, HEX #E74C3C\n",
    "  \n",
    "---\n",
    "  \n",
    "**Links**\n",
    "  \n",
    "[NumPy Documentation](https://numpy.org/doc/stable/user/index.html#user)  \n",
    "[Pandas Documentation](https://pandas.pydata.org/docs/user_guide/index.html#user-guide)  \n",
    "[Matplotlib Documentation](https://matplotlib.org/stable/index.html)  \n",
    "[Seaborn Documentation](https://seaborn.pydata.org)  \n",
    "[Apache Spark Documentation](https://spark.apache.org/docs/latest/api/python/index.html)  \n",
    "  \n",
    "---\n",
    "  \n",
    "**Notable Functions**\n",
    "  \n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Index</th>\n",
    "    <th>Operator</th>\n",
    "    <th>Use</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>pyspark.sql.SparkSession</td>\n",
    "    <td>Main entry point for using Spark functionality</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>spark.version</td>\n",
    "    <td>Retrieves the version of Spark</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>spark.stop()</td>\n",
    "    <td>Terminates the Spark session and releases resources</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td>SparkSession.builder.master('local[*]').appName('flights').getOrCreate()</td>\n",
    "    <td>Creates a SparkSession with specific configuration</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5</td>\n",
    "    <td>spark.count()</td>\n",
    "    <td>Counts the number of rows in a DataFrame</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6</td>\n",
    "    <td>spark.show()</td>\n",
    "    <td>Displays the contents of a DataFrame</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>7</td>\n",
    "    <td>pyspark.sql.types.StructType</td>\n",
    "    <td>Defines the structure for a DataFrame's schema</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>8</td>\n",
    "    <td>pyspark.sql.types.StructField</td>\n",
    "    <td>Defines a single field within a schema</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>9</td>\n",
    "    <td>pyspark.sql.types.IntegerType</td>\n",
    "    <td>Represents the integer data type in a schema</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10</td>\n",
    "    <td>pyspark.sql.types.StringType</td>\n",
    "    <td>Represents the string data type in a schema</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>11</td>\n",
    "    <td>spark.read.csv</td>\n",
    "    <td>Reads data from a CSV file into a DataFrame</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>12</td>\n",
    "    <td>spark.printSchema()</td>\n",
    "    <td>Prints the schema of a DataFrame</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>13</td>\n",
    "    <td>spark.filter</td>\n",
    "    <td>Filters rows from a DataFrame based on a condition</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>14</td>\n",
    "    <td>spark.select</td>\n",
    "    <td>Selects specific columns from a DataFrame</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>15</td>\n",
    "    <td>spark.dropna</td>\n",
    "    <td>Removes rows with missing values from a DataFrame</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>16</td>\n",
    "    <td>spark.drop</td>\n",
    "    <td>Removes specified columns from a DataFrame</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>17</td>\n",
    "    <td>pyspark.sql.functions.round</td>\n",
    "    <td>Rounds the values in a column</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>18</td>\n",
    "    <td>spark.withColumn</td>\n",
    "    <td>Adds a new column or replaces an existing one</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>19</td>\n",
    "    <td>pyspark.ml.feature.StringIndexer</td>\n",
    "    <td>Converts string labels into numerical indices</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>20</td>\n",
    "    <td>spark.fit</td>\n",
    "    <td>Trains a machine learning model</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>21</td>\n",
    "    <td>spark.transform</td>\n",
    "    <td>Applies a transformation to a DataFrame</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>22</td>\n",
    "    <td>pyspark.ml.feature.VectorAssembler</td>\n",
    "    <td>Combines multiple columns into a single vector column</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>23</td>\n",
    "    <td>spark.randomSplit</td>\n",
    "    <td>Splits a DataFrame into random subsets</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>24</td>\n",
    "    <td>pyspark.ml.classification.DecisionTreeClassifier</td>\n",
    "    <td>Creates a decision tree classification model</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>25</td>\n",
    "    <td>spark.groupBy</td>\n",
    "    <td>Groups data in a DataFrame by specified columns</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>26</td>\n",
    "    <td>pyspark.ml.classification.LogisticRegression</td>\n",
    "    <td>Creates a logistic regression classification model</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>27</td>\n",
    "    <td>pyspark.ml.evaluation.MulticlassClassificationEvaluator</td>\n",
    "    <td>Evaluates multiclass classification models</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>28</td>\n",
    "    <td>pyspark.ml.evaluation.BinaryClassificationEvaluator</td>\n",
    "    <td>Evaluates binary classification models</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>29</td>\n",
    "    <td>pyspark.sql.functions.regexp_replace</td>\n",
    "    <td>Replaces occurrences of a pattern in a string column</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>30</td>\n",
    "    <td>pyspark.ml.feature.Tokenizer</td>\n",
    "    <td>Splits text into words (tokens)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>31</td>\n",
    "    <td>pyspark.ml.feature.StopWordsRemover</td>\n",
    "    <td>Removes common words (stop words) from text</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>32</td>\n",
    "    <td>pyspark.ml.feature.HashingTF</td>\n",
    "    <td>Converts text data into numerical vectors</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>33</td>\n",
    "    <td>pyspark.ml.feature.IDF</td>\n",
    "    <td>Applies Inverse Document Frequency (IDF) to text vectors</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>34</td>\n",
    "    <td>pyspark.ml.feature.OneHotEncoder</td>\n",
    "    <td>This is different from scikit-learnâ€™s OneHotEncoder, which keeps all categories. The output vectors are sparse.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>35</td>\n",
    "    <td>pyspark.ml.regression.LinearRegression</td>\n",
    "    <td>This supports multiple types of regularization: none (a.k.a. ordinary least squares), L2 (ridge regression), L1 (Lasso), L2 + L1 (elastic net)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>36</td>\n",
    "    <td>pyspark.ml.evaluation.RegressionEvaluator</td>\n",
    "    <td>Evaluator for Regression, which expects input columns prediction, label and an optional weight column.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>37</td>\n",
    "    <td>pyspark.ml.feature.Bucketizer</td>\n",
    "    <td>Maps a column of continuous features to a column of feature buckets. Since 3.0.0, Bucketizer can map multiple columns at once by setting the inputCols parameter. Note that when both the inputCol and inputCols parameters are set, an Exception will be thrown. The splits parameter is only used for single column usage, and splitsArray is for multiple columns.</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "---\n",
    "  \n",
    "**Language and Library Information**  \n",
    "  \n",
    "Python 3.11.0  \n",
    "  \n",
    "Name: numpy  \n",
    "Version: 1.24.3  \n",
    "Summary: Fundamental package for array computing in Python  \n",
    "  \n",
    "Name: pandas  \n",
    "Version: 2.0.3  \n",
    "Summary: Powerful data structures for data analysis, time series, and statistics  \n",
    "  \n",
    "Name: matplotlib  \n",
    "Version: 3.7.2  \n",
    "Summary: Python plotting package  \n",
    "  \n",
    "Name: seaborn  \n",
    "Version: 0.12.2  \n",
    "Summary: Statistical data visualization  \n",
    "  \n",
    "Name: pyspark  \n",
    "Version: 3.4.1  \n",
    "Summary: Apache Spark Python API  \n",
    "  \n",
    "---\n",
    "  \n",
    "**Miscellaneous Notes**\n",
    "  \n",
    "<span style='color:#7393B3'>NOTE:</span>  \n",
    "  \n",
    "`python3.11 -m IPython` : Runs python3.11 interactive jupyter notebook in terminal.\n",
    "  \n",
    "`nohup ./relo_csv_D2S.sh > ./output/relo_csv_D2S.log &` : Runs csv data pipeline in headless log.  \n",
    "  \n",
    "`print(inspect.getsourcelines(test))` : Get self-defined function schema  \n",
    "  \n",
    "<span style='color:#7393B3'>NOTE:</span>  \n",
    "  \n",
    "Snippet to plot all built-in matplotlib styles :\n",
    "  \n",
    "```python\n",
    "\n",
    "x = np.arange(-2, 8, .1)\n",
    "y = 0.1 * x ** 3 - x ** 2 + 3 * x + 2\n",
    "fig = plt.figure(dpi=100, figsize=(10, 20), tight_layout=True)\n",
    "available = ['default'] + plt.style.available\n",
    "for i, style in enumerate(available):\n",
    "    with plt.style.context(style):\n",
    "        ax = fig.add_subplot(10, 3, i + 1)\n",
    "        ax.plot(x, y)\n",
    "    ax.set_title(style)\n",
    "```\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                  # Numerical Python:         Arrays and linear algebra\n",
    "import pandas as pd                 # Panel Datasets:           Dataset manipulation\n",
    "import matplotlib.pyplot as plt     # MATLAB Plotting Library:  Visualizations\n",
    "import seaborn as sns               # Seaborn:                  Visualizations\n",
    "import pyspark                      # Apache Spark:             Cluster Computing\n",
    "\n",
    "# Setting a standard figure size\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "# Set the maximum number of columns to be displayed\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "  \n",
    "Welcome back! So far you've learned how to build classifier and regression models using Spark. In this chapter you'll learn how to make those models better. You'll start by taking a look at pipelines, which will seriously streamline your workflow. They will also help to ensure that training and testing data are treated consistently and that no leakage of information between these two sets takes place.\n",
    "  \n",
    "**Leakage?**\n",
    "  \n",
    "What do I mean by leakage? Most of the actions you've been using involve both a `.fit()` and a `.transform()` method. Those methods have been applied in a fairly relaxed way. But to get really robust results you need to be careful only to apply the `.fit()` method to training data. Why? Because if a `.fit()` method is applied to *any* of the testing data then the model will effectively have seen those data during the training phase, so the results of testing will no longer be objective. The `.transform()` method, on the other hand, can be applied to both training and testing data since it does not result in any changes in the underlying model.\n",
    "  \n",
    "<center><img src='../_images/pipeline-leakage-in-pyspark.png' alt='img' width='740'></center>\n",
    "  \n",
    "**A leaky model**\n",
    "  \n",
    "A figure should make this clearer. Leakage occurs whenever a `.fit()` method is applied to testing data. Suppose that you fit a model using both the training and testing data. The model would then already have *seen* the testing data, so using those data to test the model would not be fair: of course the model will perform well on data which has been used for training! This sounds obvious, but care must be taken not to fall into this trap. Remember that there are normally multiple stages in building a model and if the `.fit()` method in *any* of those stages is applied to the testing data then the model is compromised.\n",
    "  \n",
    "**A watertight model**\n",
    "  \n",
    "However, if you are careful to only apply `.fit()` to the training data then your model will be in good shape. When it comes to testing it will not have seen *any* of the testing data and the test results will be completely objective. Luckily a pipeline will make it easier to avoid leakage because it simplifies the training and testing process.\n",
    "  \n",
    "<center><img src='../_images/pipeline-leakage-in-pyspark1.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Pipeline**\n",
    "  \n",
    "A pipeline is a mechanism to combine a series of steps. Rather than applying each of the steps individually, they are all grouped together and applied as a single unit.\n",
    "  \n",
    "<center><img src='../_images/pipeline-leakage-in-pyspark2.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Cars model: Steps**\n",
    "  \n",
    "Let's return to our cars regression model. Recall that there were a number of steps involved: - using a string indexer to convert the type column to indexed values;  \n",
    "  \n",
    "- applying a one-hot encoder to convert those indexed values into dummy variables; then \n",
    "- assembling a set of predictors into a single features column; and finally \n",
    "- building a regression model.\n",
    "  \n",
    "<center><img src='../_images/pipeline-leakage-in-pyspark3.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Cars model: Applying steps**\n",
    "  \n",
    "Let's map out the process of applying those steps. - First you fit the indexer to the training data. Then you call the `.transform()` method on the training data to add the indexed column. - Then you call the `.transform()` method on the testing data to add the indexed column there too. Note that the testing data was not used to fit the indexer. Next you do the same things for the one-hot encoder, fitting to the training data and then using the fitted encoder to update the training and testing data sets. The assembler is next. In this case there is no `.fit()` method, so you simply apply the `.transform()` method to the training and testing data. Finally the data are ready. You fit the regression model to the training data and then use the model to make predictions on the testing data. Throughout the process you've been careful to keep the testing data out of the training process. But this is hard work and it's easy enough to slip up.\n",
    "  \n",
    "<center><img src='../_images/pipeline-leakage-in-pyspark4.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Cars model: Pipeline**\n",
    "  \n",
    "A pipeline makes training and testing a complicated model a lot easier. The Pipeline class lives in the `ml` sub-module. You create a pipeline by specifying a sequence of `'stages='`, where each stage corresponds to a step in the model building process. The `'stages='` are executed in order. Now, rather than calling the `.fit()` and `.transform()` methods for each stage, you simply call the `.fit()` method for the pipeline on the training data. Each of the `'stages='` in the pipeline is then automatically applied to the training data in turn. This will systematically apply the `.fit()` and `.transform()` methods for each stage in the pipeline. The trained pipeline can then be used to make predictions on the testing data by calling its `.transform()` method. The pipeline `.transform()` method will only call the `.transform()` method for each of the `'stages='` in the pipeline. Isn't that simple?\n",
    "  \n",
    "<center><img src='../_images/pipeline-leakage-in-pyspark5.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Cars model: Stages**\n",
    "  \n",
    "You can access the `'stages='` in the pipeline by using the `.stages` attribute, which is a list. You pick out individual `.stages` by indexing into the list. For example, to access the regression component of the pipeline you'd use an index of 3. Having access to that component makes it possible to get the intercept and coefficients for the trained `LinearRegression` model.\n",
    "  \n",
    "<center><img src='../_images/pipeline-leakage-in-pyspark6.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Pipelines streamline workflow!**\n",
    "  \n",
    "Pipelines make your code easier to read and maintain. Let's try them out with our flights model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight duration model: Pipeline stages\n",
    "  \n",
    "You're going to create the stages for the flights duration model pipeline. You will use these in the next exercise to build a pipeline and to create a regression model.\n",
    "  \n",
    "The `StringIndexer`, `OneHotEncoder`, `VectorAssembler` and `LinearRegression` classes are already imported.\n",
    "  \n",
    "---\n",
    "  \n",
    "1. Create an indexer to convert the `'org'` column into an indexed column called `'org_idx'`.\n",
    "2. Create a one-hot encoder to convert the `'org_idx'` and `'dow'` columns into dummy variable columns called `'org_dummy'` and `'dow_dummy'`.\n",
    "3. Create an assembler which will combine the `'km'` column with the two dummy variable columns. The output column should be called `'features'`.\n",
    "4. Create a linear regression object to predict flight duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/29 00:14:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains 275000 record(s).\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 10| 10|  1|     OO|  5836|ORD| 157|  8.18|      51|   27|\n",
      "|  1|  4|  1|     OO|  5866|ORD| 466|  15.5|     102| null|\n",
      "| 11| 22|  1|     OO|  6016|ORD| 738|  7.17|     127|  -19|\n",
      "|  2| 14|  5|     B6|   199|JFK|2248| 21.17|     365|   60|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 386| 12.92|      85|   22|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- mon: integer (nullable = true)\n",
      " |-- dom: integer (nullable = true)\n",
      " |-- dow: integer (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- org: string (nullable = true)\n",
      " |-- mile: integer (nullable = true)\n",
      " |-- depart: double (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- delay: integer (nullable = true)\n",
      "\n",
      "None\n",
      "[('mon', 'int'), ('dom', 'int'), ('dow', 'int'), ('carrier', 'string'), ('flight', 'int'), ('org', 'string'), ('mile', 'int'), ('depart', 'double'), ('duration', 'int'), ('delay', 'int')]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('flights').getOrCreate()\n",
    "\n",
    "# Read data from CSV file\n",
    "flights = spark.read.csv('../_datasets/flights-larger.csv', sep=',', header=True, inferSchema=True, nullValue='NA')\n",
    "\n",
    "# Get number of records \n",
    "print('The data contains {} record(s).'.format(flights.count()))\n",
    "\n",
    "# View the first five rows\n",
    "flights.show(5)\n",
    "\n",
    "# Check column data types\n",
    "print(flights.printSchema())\n",
    "print(flights.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "# Convert 'mile' to 'km' and drop 'mile' column\n",
    "flights = flights.withColumn('km', round(flights.mile * 1.60934, 0)).drop('mile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Convert Categorical strings to index values\n",
    "indexer = StringIndexer(inputCol='org', outputCol='org_idx')\n",
    "\n",
    "# One-hot encode index values\n",
    "onehot = OneHotEncoder(\n",
    "    inputCols=['org_idx', 'dow'],\n",
    "    outputCols=['org_dummy', 'dow_dummy']\n",
    ")\n",
    "\n",
    "# Assemble predictors into a single column\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['km', 'org_dummy', 'dow_dummy'],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "# A linear regression object\n",
    "regression = LinearRegression(labelCol='duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! The stages are now ready for you to build a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight duration model: Pipeline model\n",
    "  \n",
    "You're now ready to put those stages together in a pipeline.\n",
    "  \n",
    "You'll construct the pipeline and then train the pipeline on the training data. This will apply each of the individual stages in the pipeline to the training data in turn. None of the stages will be exposed to the testing data at all: there will be no leakage!\n",
    "  \n",
    "Once the entire pipeline has been trained it will then be used to make predictions on the testing data.\n",
    "  \n",
    "The data are available as `flights`, which has been randomly split into `flights_train` and `flights_test`.\n",
    "  \n",
    "---\n",
    "  \n",
    "1. Import the class for creating a pipeline.\n",
    "2. Create a pipeline object and specify the `indexer`, `onehot`, `assembler` and `regression` stages, in this order.\n",
    "3. Train the pipeline on the training data.\n",
    "4. Make predictions on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/29 00:15:00 WARN Instrumentation: [17ff8f13] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/08/29 00:15:06 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/08/29 00:15:10 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "flights_train, flights_test = flights.randomSplit([0.8, 0.2], seed=999)\n",
    "\n",
    "# Construct a pipeline\n",
    "pipeline = Pipeline(stages=[indexer, onehot, assembler, regression])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "pipeline = pipeline.fit(flights_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = pipeline.transform(flights_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! A pipeline makes your code easier to read and maintain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMS spam pipeline\n",
    "  \n",
    "You haven't looked at the SMS data for quite a while. Last time we did the following:\n",
    "  \n",
    "- split the text into tokens\n",
    "- removed stop words\n",
    "- applied the hashing trick\n",
    "- converted the data from counts to IDF and\n",
    "- trained a logistic regression model.\n",
    "  \n",
    "Each of these steps was done independently. This seems like a great application for a pipeline!\n",
    "  \n",
    "The `Pipeline` and `LogisticRegression` classes have already been imported into the session, so you don't need to worry about that!\n",
    "  \n",
    "---\n",
    "  \n",
    "1. Create an object for splitting text into tokens.\n",
    "2. Create an object to remove stop words. Rather than explicitly giving the input column name, use the `.getOutputCol()` method on the previous object.\n",
    "3. Create objects for applying the hashing trick and transforming the data into a TF-IDF. Use the `.getOutputCol()` method again.\n",
    "4. Create a pipeline which wraps all of the above steps as well as an object to create a Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+\n",
      "| id|                text|label|\n",
      "+---+--------------------+-----+\n",
      "|  1|Sorry, I'll call ...|    0|\n",
      "|  2|Dont worry. I gue...|    0|\n",
      "|  3|Call FREEPHONE 08...|    1|\n",
      "|  4|Win a 1000 cash p...|    1|\n",
      "|  5|Go until jurong p...|    0|\n",
      "+---+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "# Specify column names and types\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"text\", StringType()),\n",
    "    StructField(\"label\", IntegerType())\n",
    "])\n",
    "\n",
    "# Read data from CSV file\n",
    "sms = spark.read.csv('../_datasets/sms.csv', sep=';', header=False, schema=schema, nullValue='NA')\n",
    "\n",
    "sms.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Break text into tokens at non-word characters\n",
    "tokenizer = Tokenizer(inputCol='text', outputCol='words')\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='terms')\n",
    "\n",
    "# Apply the hashing trick and transform to TF-IDF\n",
    "hasher = HashingTF(inputCol=remover.getOutputCol(), outputCol='hash')\n",
    "idf = IDF(inputCol=hasher.getOutputCol(), outputCol='features')\n",
    "\n",
    "# Create a logistic regression object and add everything to a pipeline\n",
    "logistic = LogisticRegression()\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hasher, idf, logistic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! Isn't that a lot simpler than applying each stage separately?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "  \n",
    "Up until now you've been testing models using a rather simple technique: randomly splitting the data into training and testing sets, training the model on the training data and then evaluating its performance on the testing set. There's one major drawback to this approach: you only get one estimate of the model performance. You would have a more robust idea of how well a model works if you were able to test it multiple times. This is precisely the idea behind cross-validation.\n",
    "  \n",
    "**CV - complete data**\n",
    "  \n",
    "You start out with the full set of data.\n",
    "  \n",
    "**CV - train/test split**\n",
    "  \n",
    "You still split these data into a training set and a testing set. Remember that before splitting it's important to first randomize the data so that the distributions in the training and testing data are similar.\n",
    "  \n",
    "**CV - multiple folds**\n",
    "  \n",
    "You then split the training data into a number of partitions or \"folds\". The number of folds normally factors into the name of the technique. For example, if you split into five folds then you'd talk about 5-fold cross-validation.\n",
    "  \n",
    "<center><img src='../_images/cross-validation-in-pyspark.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Fold upon fold - first fold**\n",
    "  \n",
    "Once the training data have been split into folds you can start cross-validating. First keep aside the data in the first fold. Train a model on the remaining four folds. Then evaluate that model on the data from the first fold. This will give the first value for the evaluation metric.\n",
    "  \n",
    "**Fold upon fold - second fold**\n",
    "  \n",
    "Next you move onto the second fold, where the same process is repeated: data in the second fold are set aside for testing while the remaining four folds are used to train a model. That model is tested on the second fold data, yielding the second value for the evaluation metric.\n",
    "  \n",
    "**Fold upon fold - other folds**\n",
    "  \n",
    "You repeat the process for the remaining folds. Each of the folds is used in turn as testing data and you end up with as many values for the evaluation metric as there are folds. At this point you are in a position to calculate the average of the evaluation metric over all folds, which is a much more robust measure of model performance than a single value.\n",
    "  \n",
    "<center><img src='../_images/cross-validation-in-pyspark1.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Cars revisited**\n",
    "  \n",
    "Let's see how this works in practice. Remember the cars data? Of course you do. You're going to build a cross-validated regression model to predict consumption.\n",
    "  \n",
    "<center><img src='../_images/cross-validation-in-pyspark2.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Estimator and evaluator**\n",
    "  \n",
    "Here are the first two ingredients which you need to perform cross-validation: \n",
    "  \n",
    "- an estimator, which builds the model and is often a pipeline; and \n",
    "- an evaluator, which quantifies how well a model works on testing data. We've seen both of these a few times already.\n",
    "  \n",
    "<center><img src='../_images/cross-validation-in-pyspark3.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Grid and cross-validator**\n",
    "  \n",
    "Now the final ingredients. You'll need two new classes, `CrossValidator` and `ParamGridBuilder`, both from the `tuning` sub-module. You'll create a parameter grid, which you'll leave empty for the moment, but will return to in detail during the next lesson.  \n",
    "  \n",
    "Finally you have everything required to create a cross-validator object:  \n",
    "  \n",
    "- an estimator, which is the linear regression model, \n",
    "- an empty grid of parameters for the estimator and \n",
    "- an evaluator which will calculate the RMSE. You can optionally specify the number of folds (which defaults to three) and a random number seed for repeatability.\n",
    "  \n",
    "<center><img src='../_images/cross-validation-in-pyspark4.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Cross-validators need training too**\n",
    "  \n",
    "The cross-validator has a `.fit()` method which will apply the cross-validation procedure to the training data. You can then look at the average RMSE calculated across all of the folds. This is a more robust measure of model performance because it is based on multiple train/test splits. Note that the average metric is returned as a list. You'll see why in the next lesson.\n",
    "  \n",
    "<center><img src='../_images/cross-validation-in-pyspark5.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Cross-validators act like models**\n",
    "  \n",
    "The trained cross-validator object acts just like any other model. It has a `.transform()` method, which can be used to make predictions on new data. If we evaluate the predictions on the original testing data then we find a smaller value for the RMSE than we obtained using cross-validation. This means that a simple train-test split would have given an overly optimistic view on model performance.\n",
    "  \n",
    "<center><img src='../_images/cross-validation-in-pyspark6.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Cross-validate all the models!**\n",
    "  \n",
    "Let's give cross-validation a try on our flights model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validating simple flight duration model\n",
    "  \n",
    "You've already built a few models for predicting flight duration and evaluated them with a simple train/test split. However, cross-validation provides a much better way to evaluate model performance.\n",
    "  \n",
    "In this exercise you're going to train a simple model for flight duration using cross-validation. Travel time is usually strongly correlated with distance, so using the `'km'` column alone should give a decent model.\n",
    "  \n",
    "The data have been randomly split into `flights_train` and `flights_test`.\n",
    "  \n",
    "The following classes have already been imported: `LinearRegression`, `RegressionEvaluator`, `ParamGridBuilder` and `CrossValidator`.\n",
    "  \n",
    "---\n",
    "  \n",
    "1. Create an empty parameter grid.\n",
    "2. Create objects for building and evaluating a linear regression model. The model should predict the \"duration\" field.\n",
    "3. Create a cross-validator object. Provide values for the `estimator=`, `estimatorParamMaps=` and `evaluator=` arguments. Choose 5-fold cross validation.\n",
    "4. Train and test the model across multiple folds of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+------+--------+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|    km|features|\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+--------+\n",
      "| 10| 10|  1|     OO|  5836|ORD|  8.18|      51|   27| 253.0| [253.0]|\n",
      "|  1|  4|  1|     OO|  5866|ORD|  15.5|     102| null| 750.0| [750.0]|\n",
      "| 11| 22|  1|     OO|  6016|ORD|  7.17|     127|  -19|1188.0|[1188.0]|\n",
      "|  2| 14|  5|     B6|   199|JFK| 21.17|     365|   60|3618.0|[3618.0]|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 12.92|      85|   22| 621.0| [621.0]|\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=['km'],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "flights = assembler.transform(flights.drop('features'))\n",
    "\n",
    "flights.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/29 00:15:22 WARN Instrumentation: [9760c03e] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/08/29 00:15:41 WARN Instrumentation: [5909b433] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/08/29 00:16:01 WARN Instrumentation: [03d63793] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/08/29 00:16:20 WARN Instrumentation: [500343f5] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/08/29 00:16:32 WARN Instrumentation: [133d3487] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/08/29 00:16:46 WARN Instrumentation: [b4582f0c] regParam is zero, which might cause numerical instability and overfitting.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "flights_train, flights_test = flights.randomSplit([0.8, 0.2], seed=999)\n",
    "\n",
    "# Create an empty parameter grid\n",
    "params = ParamGridBuilder().build()\n",
    "\n",
    "# Create objects for building and evaluating a regression model\n",
    "regression = LinearRegression(labelCol='duration')\n",
    "evaluator = RegressionEvaluator(labelCol='duration')\n",
    "\n",
    "# Create a cross validator\n",
    "cv = CrossValidator(\n",
    "    estimator=regression,\n",
    "    estimatorParamMaps=params,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=5\n",
    ")\n",
    "\n",
    "# Train and test model on multiple folds of the training data\n",
    "cv = cv.fit(flights_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's cross validate a model pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validating flight duration model pipeline\n",
    "  \n",
    "The cross-validated model that you just built was simple, using `'km'` alone to predict `'duration'`.\n",
    "  \n",
    "Another important predictor of flight duration is the origin airport. Flights generally take longer to get into the air from busy airports. Let's see if adding this predictor improves the model!\n",
    "  \n",
    "In this exercise you'll add the `'org'` field to the model. However, since `'org'` is categorical, there's more work to be done before it can be included: it must first be transformed to an index and then one-hot encoded before being assembled with `'km'` and used to build the regression model. We'll wrap these operations up in a pipeline.\n",
    "  \n",
    "The following objects have already been created:\n",
    "  \n",
    "- `params` â€” an empty parameter grid\n",
    "- `evaluator` â€” a regression evaluator\n",
    "- `regression` â€” a `LinearRegression` object with `labelCol='duration'`.\n",
    "  \n",
    "The `StringIndexer`, `OneHotEncoder`, `VectorAssembler` and `CrossValidator` classes have already been imported.\n",
    "  \n",
    "---\n",
    "  \n",
    "1. Create a string indexer. Specify the input and output fields as `'org'` and `'org_idx'`.\n",
    "2. Create a one-hot encoder. Name the output field `'org_dummy'`.\n",
    "3. Assemble the `'km'` and `'org_dummy'` fields into a single field called `'features'`.\n",
    "4. Create a pipeline using the following operations: string indexer, one-hot encoder, assembler and linear regression. Use this to create a cross-validator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty parameter grid\n",
    "params = ParamGridBuilder().build()\n",
    "\n",
    "# Create regression model\n",
    "regression = LinearRegression(labelCol='duration')\n",
    "evaluator = RegressionEvaluator(labelCol='duration')\n",
    "\n",
    "# Create an indexer for the org field\n",
    "indexer = StringIndexer(inputCol='org', outputCol='org_idx')\n",
    "\n",
    "# Create an one-hot encoder for the indexed 'org' field\n",
    "onehot = OneHotEncoder(inputCol='org_idx', outputCol='org_dummy')\n",
    "\n",
    "# Assemble the 'km' and one-hot encoded fields\n",
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy'], outputCol='features')\n",
    "\n",
    "# Create a pipeline and cross-validator\n",
    "pipeline = Pipeline(stages=[indexer, onehot, assembler, regression])\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=params,\n",
    "    evaluator=evaluator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping operations in a pipeline makes cross validating the entire workflow easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "  \n",
    "So far you've been using the default parameters for almost everything. You've built some decent models, but they could probably be improved by choosing better model parameters.\n",
    "  \n",
    "**Tuning**\n",
    "  \n",
    "There is no universal \"best\" set of parameters for a particular model. The optimal choice of parameters will depend on the data and the modeling goal. The idea is relatively simple, you build a selection of models, one for each set of model parameters. Then you evaluate those models and choose the best one.\n",
    "  \n",
    "<center><img src='../_images/grid-search-in-pyspark.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Cars revisited (again)**\n",
    "  \n",
    "You'll be looking at the fuel consumption regression model again.\n",
    "  \n",
    "<center><img src='../_images/grid-search-in-pyspark1.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Fuel consumption with intercept**\n",
    "  \n",
    "You'll start by doing something simple, comparing a linear regression model with an intercept to one that passes through the origin. By default a linear regression model will always fit an intercept, but you're going to be explicit and specify the `fitIntercept=` parameter as True. You fit the model to the training data and then calculate the RMSE for the testing data.\n",
    "  \n",
    "<center><img src='../_images/grid-search-in-pyspark2.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Fuel consumption without intercept**\n",
    "  \n",
    "Next you repeat the process, but specify False for the `fitIntercept=` parameter. Now you are creating a model which passes through the origin. When you evaluate this model you find that the RMSE is higher. So, comparing these two models you'd naturally choose the first one because it has a lower RMSE. However, there's a problem with this approach. Just getting a single estimate of RMSE is not very robust. It'd be better to make this comparison using cross-validation. You also have to manually build the models for the two different parameter values. It'd be great if that were automated.\n",
    "  \n",
    "<center><img src='../_images/grid-search-in-pyspark3.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Parameter grid**\n",
    "  \n",
    "You can systematically evaluate a model across a grid of parameter values using a technique known as grid search. To do this you need to set up a parameter grid. You actually saw this in the previous lesson, where you simply created an empty grid. Now you are going to add points to the grid. First you create a grid builder and then you add one or more grids. At present there's just one grid, which takes two values for the `fitIntercept=` parameter. Call the `.build()` method to construct the grid. A separate model will be built for each point in the grid. You can check how many models this corresponds to and, of course, this is just two.\n",
    "  \n",
    "<center><img src='../_images/grid-search-in-pyspark4.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Grid search with cross-validation**\n",
    "  \n",
    "Now you create a cross-validator object and fit it to the training data. This builds a bunch of models: one model for each fold and point in the parameter grid. Since there are two points in the grid and ten folds, this translates into twenty models. The cross-validator is going to loop through each of the points in the parameter grid and for each point it will create a cross-validated model using the corresponding parameter values. When you take a look at the average metrics attribute, you can see why the metric is given as a list: you get one average value for each point in the grid. The values confirm what you observed before: the model that includes an intercept is superior to the model without an intercept.\n",
    "  \n",
    "<center><img src='../_images/grid-search-in-pyspark5.png' alt='img' width='740'></center>\n",
    "  \n",
    "**The best model & parameters**\n",
    "  \n",
    "Our goal was to get the best model for the data. You retrieve this using the appropriately named `.bestModel` attribute. But it's not actually necessary to work with this directly because the cross-validator object will behave like the best model. So, you can use it directly to make predictions on the testing data. Of course, you want to know what the best parameter value is and you can retrieve this using the `.explainParam()` method. As expected the best value for the `fitIntercept=` parameter is True. You can see this after the word \"current\" in the output.\n",
    "  \n",
    "<center><img src='../_images/grid-search-in-pyspark6.png' alt='img' width='740'></center>\n",
    "  \n",
    "**A more complicated grid**\n",
    "  \n",
    "It's possible to add more parameters to the grid. Here, in addition to whether or not to include an intercept, you're also considering a selection of values for the regularization parameter and the elastic net parameter. Of course, the more parameters and values you add to the grid, the more models you have to evaluate. Because each of these models will be evaluated using cross-validation, this might take a little while. But it will be time well spent, because the model that you get back will in principle be much better than what you would have obtained by just using the default parameters.\n",
    "  \n",
    "<center><img src='../_images/grid-search-in-pyspark7.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Find the best parameters!**\n",
    "  \n",
    "Let's apply grid search on the flights and SMS models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing flights linear regression\n",
    "  \n",
    "Up until now you've been using the default hyper-parameters when building your models. In this exercise you'll use cross validation to choose an optimal (or close to optimal) set of model hyper-parameters.\n",
    "  \n",
    "The following have already been created:\n",
    "  \n",
    "- `regression` â€” a `LinearRegression` object\n",
    "- `pipeline` â€” a pipeline with string indexer, one-hot encoder, vector assembler and linear regression and\n",
    "- `evaluator` â€” a `RegressionEvaluator` object.\n",
    "  \n",
    "---\n",
    "  \n",
    "1. Create a parameter grid builder.\n",
    "2. Add grids for with `regression.regParam` (values 0.01, 0.1, 1.0, and 10.0) and `regression.elasticNetParam` (values 0.0, 0.5, and 1.0).\n",
    "3. Build the grid.\n",
    "4. Create a cross validator, specifying five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models to be tested:  12\n"
     ]
    }
   ],
   "source": [
    "# Create parameter grid\n",
    "params = ParamGridBuilder()\n",
    "\n",
    "# Add grids for two parameters\n",
    "params = params.addGrid(regression.regParam, [0.01, 0.1, 1.0, 10.0])\\\n",
    "               .addGrid(regression.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "\n",
    "# Build the parameter grid\n",
    "params = params.build()\n",
    "print('Number of models to be tested: ', len(params))\n",
    "\n",
    "# Create cross-validator\n",
    "cv = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=params, \n",
    "    evaluator=evaluator, \n",
    "    numFolds=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Multiple models are built effortlessly using grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dissecting the best flight duration model\n",
    "  \n",
    "You just set up a `CrossValidator` to find good parameters for the linear regression model predicting flight duration.\n",
    "  \n",
    "The model pipeline has multiple stages (objects of type `StringIndexer`, `OneHotEncoder`, `VectorAssembler` and `LinearRegression`), which operate in sequence. The `stages=` are available as the stages attribute on the pipeline object. They are represented by a list and the stages are executed in the sequence in which they appear in the list.\n",
    "  \n",
    "Now you're going to take a closer look at the pipeline, split out the stages and use it to make predictions on the testing data.\n",
    "  \n",
    "The following objects have already been created:\n",
    "  \n",
    "- `cv` â€” a trained `CrossValidatorModel` object and\n",
    "- `evaluator` â€” a `RegressionEvaluator` object.\n",
    "  \n",
    "The flights data have been randomly split into `flights_train` and `flights_test`.\n",
    "  \n",
    "---\n",
    "  \n",
    "1. Retrieve the best model.\n",
    "2. Look at the stages in the best model.\n",
    "3. Isolate the linear regression stage and extract its parameters.\n",
    "4. Use the best model to generate predictions on the testing data and calculate the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:>                                                         (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StringIndexerModel: uid=StringIndexer_151d4c3ab0aa, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_c0c929e239e2, dropLast=true, handleInvalid=error, VectorAssembler_afc3318dcf9a, LinearRegressionModel: uid=LinearRegression_3e94151ae75b, numFeatures=8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 396:===================>                                     (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  11.149352212449399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Drop the existed feature column\n",
    "flights_train, flights_test = flights.drop('features').randomSplit([0.8, 0.2], seed=999)\n",
    "\n",
    "# Train the data\n",
    "cvModel = cv.fit(flights_train)\n",
    "\n",
    "# Get the best model from cross validation\n",
    "best_model = cvModel.bestModel\n",
    "\n",
    "# Look at the stages in the best model\n",
    "print(best_model.stages)\n",
    "\n",
    "# Get the parameters for the LinearRegression object in the best model\n",
    "best_model.stages[3].extractParamMap()\n",
    "\n",
    "# Generate predictions on test data using the best model then calculate RMSE\n",
    "predictions = best_model.transform(flights_test)\n",
    "print('RMSE: ',evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model performs pretty well on the testing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMS spam optimised\n",
    "  \n",
    "The pipeline you built earlier for the SMS spam model used the default parameters for all of the elements in the pipeline. It's very unlikely that these parameters will give a particularly good model though. In this exercise you're going to run the pipeline for a selection of parameter values. We're going to do this in a systematic way: the values for each of the parameters will be laid out on a grid and then pipeline will systematically run across each point in the grid.\n",
    "  \n",
    "In this exercise you'll set up a parameter grid which can be used with cross validation to choose a good set of parameters for the SMS spam classifier.\n",
    "  \n",
    "The following are already defined:\n",
    "  \n",
    "- `hasher` â€” a `HashingTF` object and\n",
    "- `logistic` â€” a `LogisticRegression` object.\n",
    "  \n",
    "---\n",
    "  \n",
    "1. Create a parameter grid builder object.\n",
    "2. Add grid points for `numFeatures=` and binary parameters to the `HashingTF` object, giving values 1024, 4096 and 16384, and `True` and `False`, respectively.\n",
    "3. Add grid points for `regParam=` and `elasticNetParam=` parameters to the `LogisticRegression` object, giving values of 0.01, 0.1, 1.0 and 10.0, and 0.0, 0.5, and 1.0 respectively.\n",
    "4. Build the parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models to be tested:  72\n"
     ]
    }
   ],
   "source": [
    "# Create parameter grid\n",
    "params = ParamGridBuilder()\n",
    "\n",
    "# Add grid for hashing trick parameters\n",
    "params = params.addGrid(hasher.numFeatures, (1024, 4096, 16384)).addGrid(hasher.binary, (True, False))\n",
    "\n",
    "# Add grid for logistic regression parameters\n",
    "params = params.addGrid(logistic.regParam, (0.01, 0.1, 1.0, 10.0))\\\n",
    "    .addGrid(logistic.elasticNetParam, (0.0, 0.5, 1.0))\n",
    "\n",
    "# Build parameter grid\n",
    "params = params.build()\n",
    "\n",
    "print('Number of models to be tested: ', len(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cross-validation on a pipeline makes it possible to optimise each stage in the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many models for grid search?\n",
    "  \n",
    "How many models will be built when the cross-validator below is fit to data?\n",
    "  \n",
    "```python\n",
    "params = ParamGridBuilder().addGrid(hasher.numFeatures, [1024, 4096, 16384]) \\\n",
    "                           .addGrid(hasher.binary, [True, False]) \\\n",
    "                           .addGrid(logistic.regParam, [0.01, 0.1, 1.0, 10.0]) \\\n",
    "                           .addGrid(logistic.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "                           .build()\n",
    "\n",
    "cv = CrossValidator(..., estimatorParamMaps=params, numFolds=5)\n",
    "```\n",
    "  \n",
    "---\n",
    "  \n",
    "Possible Answers\n",
    "  \n",
    "- [ ] 3\n",
    "- [ ] 5\n",
    "- [ ] 72\n",
    "- [x] 360\n",
    "  \n",
    "Correct! There are 72 points in the parameter grid and 5 folds in the cross-validator. The product is 360. It takes time to build all of those models, which is why you're not doing it here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "  \n",
    "You now know how to choose a good set of parameters for any model using cross-validation and grid search. In the final lesson you're going to learn about how models can be combined to form a collection or \"ensemble\" which is more powerful than each of the individual models alone.\n",
    "  \n",
    "**What's an ensemble?**\n",
    "  \n",
    "Simply put, an ensemble model is just a collection of models. An ensemble model combines the results from multiple models to produce better predictions than any one of those models acting alone. The concept is based on the idea of the **\"Wisdom of the Crowd\"**, which implies that the aggregated opinion of a group is better than the opinions of the individuals in that group, even if the individuals are experts.\n",
    "  \n",
    "<center><img src='../_images/ensemble-in-pyspark.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Ensemble diversity**\n",
    "  \n",
    "As the quote suggests, for this idea to be true, there must be diversity and independence in the crowd. This applies to models too: a successful ensemble requires diverse models. It does not help if all of the models in the ensemble are similar or exactly the same. Ideally each of the models in the ensemble should be different.\n",
    "  \n",
    "**Random Forest**\n",
    "  \n",
    "A Random Forest, as the name implies, is a collection of trees. To ensure that each of those trees is different, the Decision Tree algorithm is modified slightly: - each tree is trained on a different random subset of the data and - within each tree a random subset of features is used for splitting at each node. The result is a collection of trees where no two trees are the same. Within the Random Forest model, all of the trees operate in parallel.\n",
    "  \n",
    "- An ensemble of Decision Tree\n",
    "- Creating model diversity\n",
    "- Each tree trained on random subset of data\n",
    "- Random subset of features used for splitting at each node\n",
    "- No two trees in the forest should be the same\n",
    "  \n",
    "**Create a forest of trees**\n",
    "  \n",
    "Let's go back to the cars classifier yet again. You create a Random Forest model using the `RandomForestClassifier` class from the `classification` sub-module. You can select the number of trees in the forest using the `numTrees=` parameter. By default this is twenty, but we'll drop that to five so that the results are easier to interpret. As is the case with any other model, the Random Forest is fit to the training data.\n",
    "  \n",
    "<center><img src='../_images/ensemble-in-pyspark1.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Seeing the trees**\n",
    "  \n",
    "Once the model is trained it's possible to access the individual trees in the forest using the `.trees` attribute. You would not normally do this, but it's useful for illustrative purposes. There are precisely five trees in the forest, as specified. The trees are all different, as can be seen from the varying number of nodes in each tree. You can then make predictions using each tree individually.\n",
    "  \n",
    "<center><img src='../_images/ensemble-in-pyspark2.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Predictions from individual trees**\n",
    "  \n",
    "Here are the predictions of individual trees on a subset of the testing data. Each row represents predictions from each of the five trees for a specific record. In some cases all of the trees agree, but there is often some dissent amongst the models. This is precisely where the Random Forest works best: where the prediction is not clear cut. The Random Forest model creates a consensus prediction by aggregating the predictions across all of the individual trees.\n",
    "  \n",
    "<center><img src='../_images/ensemble-in-pyspark3.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Consensus predictions**\n",
    "  \n",
    "You don't need to worry about these details though because the `.transform()` method will automatically generate a consensus `'prediction'` column. It also creates a `'probability'` column which assigns aggregate probabilities to each of the outcomes.\n",
    "  \n",
    "<center><img src='../_images/ensemble-in-pyspark4.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Feature importances**\n",
    "  \n",
    "It's possible to get an idea of the relative importance of the features in the model by looking at the `.featureImportances` attribute. An importance is assigned to each feature, where a larger importance indicates a feature which makes a larger contribution to the model. Looking carefully at the importances we see that feature 4 (rpm) is the most important, while feature 0 (the number of cylinders) is the least important.\n",
    "  \n",
    "<center><img src='../_images/ensemble-in-pyspark5.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Gradient-Boosted Trees**\n",
    "  \n",
    "The second ensemble model you'll be looking at is Gradient-Boosted Trees. Again the aim is to build a collection of diverse models, but the approach is slightly different. Rather than building a set of trees that operate in parallel, now we build trees which work in series. The boosting algorithm works iteratively. First build a decision tree and add to the ensemble. Then use the ensemble to make predictions on the training data. Compare the predicted labels to the known labels. Now identify training instances where predictions were incorrect. Return to the start and train another tree which focuses on improving the incorrect predictions. As trees are added to the ensemble its predictions improve because each new tree focuses on correcting the shortcomings of the preceding trees.\n",
    "  \n",
    "Iterative boosting algorithm:\n",
    "  \n",
    "1. Build a Decision Tree and add to ensemble\n",
    "2. Predict label for each training instance using ensemble\n",
    "3. Compare predictions with known labels\n",
    "4. Emphasize training instances with incorrect predictions return to 1.\n",
    "  \n",
    "**Boosting trees**\n",
    "  \n",
    "The class for the Gradient-Boosted Tree classifier is also found in the `classification` sub-module. After creating an instance of the class you fit it to the training data.\n",
    "  \n",
    "<center><img src='../_images/ensemble-in-pyspark6.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Comparing trees**\n",
    "  \n",
    "You can make an objective comparison between a plain Decision Tree and the two ensemble models by looking at the values of AUC obtained by each of them on the testing data. Both of the ensemble methods score better than the Decision Tree. This is not too surprising since they are significantly more powerful models. It's also worth noting that these results are based on the default parameters for these models. It should be possible to get even better performance by tuning those parameters using cross-validation.\n",
    "  \n",
    "<center><img src='../_images/ensemble-in-pyspark7.png' alt='img' width='740'></center>\n",
    "  \n",
    "**Ensemble all of the models!**\n",
    "  \n",
    "In the final set of exercises you'll try out ensemble methods on the flights data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delayed flights with Gradient-Boosted Trees\n",
    "  \n",
    "You've previously built a classifier for flights likely to be delayed using a Decision Tree. In this exercise you'll compare a Decision Tree model to a Gradient-Boosted Trees model.\n",
    "  \n",
    "The flights data have been randomly split into `flights_train` and `flights_test`.\n",
    "  \n",
    "---\n",
    "  \n",
    "1. Import the classes required to create Decision Tree and Gradient-Boosted Tree classifiers.\n",
    "2. Create Decision Tree and Gradient-Boosted Tree classifiers. Train on the training data.\n",
    "3. Create an evaluator and calculate AUC on testing data for both classifiers. Which model performs better?\n",
    "4. For the Gradient-Boosted Tree classifier print the number of trees and the relative importance of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+-----------------+-----+\n",
      "|mon|depart|duration|         features|label|\n",
      "+---+------+--------+-----------------+-----+\n",
      "| 10|  8.18|      51| [10.0,8.18,51.0]|    1|\n",
      "| 11|  7.17|     127|[11.0,7.17,127.0]|    0|\n",
      "|  2| 21.17|     365|[2.0,21.17,365.0]|    1|\n",
      "|  5| 12.92|      85| [5.0,12.92,85.0]|    1|\n",
      "|  3| 13.33|     182|[3.0,13.33,182.0]|    1|\n",
      "+---+------+--------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['mon', 'depart', 'duration'], outputCol='features')\n",
    "flights = assembler.transform(flights.drop('features'))\n",
    "flights = flights.withColumn('label', (flights.delay >= 15).cast('integer'))\n",
    "flights = flights.select('mon', 'depart', 'duration', 'features', 'label')\n",
    "flights = flights.dropna()\n",
    "\n",
    "flights.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTreeRegressionModel: uid=dtr_335a8db8f72b, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_10d1426bb2bc, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_22c85d205fe8, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_0d39a2d24183, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_2ab9aafa5636, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_84d8fe399b46, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_9d353011ecc5, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_f2272df53ead, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_f5361ea59453, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_e3d6f3268400, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_84f53f5e9635, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_48221a490fc5, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_9ef189d7e2f9, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_d3f541cdae8a, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_026707c236b1, depth=5, numNodes=59, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_fe20136116c0, depth=5, numNodes=61, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_06c965aa528c, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_ed433c65cfb5, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_fbc20afc9bb6, depth=5, numNodes=63, numFeatures=3,\n",
      " DecisionTreeRegressionModel: uid=dtr_f0a6cfb635c5, depth=5, numNodes=63, numFeatures=3]\n",
      "(3,[0,1,2],[0.41444995139099444,0.2984936330906898,0.28705641551831557])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pprint import pprint\n",
    "\n",
    "flights_train, flights_test = flights.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Create model objects and train on training data\n",
    "tree = DecisionTreeClassifier().fit(flights_train)\n",
    "gbt = GBTClassifier().fit(flights_train)\n",
    "\n",
    "# Compare AUC on test data\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(tree.transform(flights_test))\n",
    "evaluator.evaluate(gbt.transform(flights_test))\n",
    "\n",
    "# Find the number of trees and the relative importance of features\n",
    "pprint(gbt.trees)\n",
    "print(gbt.featureImportances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job! A Gradient-Boosted Tree almost always provides better performance than a plain Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delayed flights with a Random Forest\n",
    "  \n",
    "In this exercise you'll bring together cross validation and ensemble methods. You'll be training a Random Forest classifier to predict delayed flights, using cross validation to choose the best values for model parameters.\n",
    "  \n",
    "You'll find good values for the following parameters:\n",
    "  \n",
    "- `featureSubsetStrategy=` â€” the number of features to consider for splitting at each node and\n",
    "- `maxDepth=` â€” the maximum number of splits along any branch.\n",
    "  \n",
    "Unfortunately building this model takes too long, so we won't be running the `.fit()` method on the pipeline.\n",
    "  \n",
    "---\n",
    "  \n",
    "1. Create a random forest classifier object.\n",
    "2. Create a parameter grid builder object. Add grid points for the `featureSubsetStrategy=` and `maxDepth=` parameters.\n",
    "3. Create binary classification evaluator.\n",
    "4. Create a cross-validator object, specifying the estimator, parameter grid and evaluator. Choose 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "# Create a parameter grid\n",
    "params = ParamGridBuilder() \\\n",
    "        .addGrid(forest.featureSubsetStrategy, ['all', 'onethird', 'sqrt', 'log2']) \\\n",
    "        .addGrid(forest.maxDepth, [2, 5, 10]) \\\n",
    "        .build()\n",
    "\n",
    "# Create a binary classification evaluator\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "# Create a cross-validator\n",
    "cv = CrossValidator(\n",
    "    estimator=forest, \n",
    "    estimatorParamMaps=params, \n",
    "    evaluator=evaluator, \n",
    "    numFolds=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! A grid search can be used to optimize all of the parameters in a model pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Random Forest\n",
    "  \n",
    "In this final exercise you'll be evaluating the results of cross-validation on a Random Forest model.\n",
    "  \n",
    "The following have already been created:\n",
    "  \n",
    "- `cv` - a cross-validator which has already been fit to the training data\n",
    "- `evaluator` â€” a `BinaryClassificationEvaluator` object and\n",
    "- `flights_test` â€” the testing data.\n",
    "  \n",
    "---\n",
    "  \n",
    "1. Print a list of average AUC metrics across all models in the parameter grid.\n",
    "2. Display the average AUC for the best model. This will be the largest AUC in the list.\n",
    "3. Print an explanation of the `maxDepth=` and `featureSubsetStrategy=` parameters for the best model.\n",
    "4. Display the AUC for the best model predictions on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/29 00:50:48 WARN DAGScheduler: Broadcasting large task binary with size 1368.1 KiB\n",
      "23/08/29 00:50:52 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 00:50:59 WARN DAGScheduler: Broadcasting large task binary with size 1359.4 KiB\n",
      "23/08/29 00:51:35 WARN DAGScheduler: Broadcasting large task binary with size 1482.5 KiB\n",
      "23/08/29 00:52:10 WARN DAGScheduler: Broadcasting large task binary with size 1402.3 KiB\n",
      "23/08/29 00:52:14 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 00:52:24 WARN DAGScheduler: Broadcasting large task binary with size 1212.5 KiB\n",
      "23/08/29 00:53:00 WARN DAGScheduler: Broadcasting large task binary with size 1402.3 KiB\n",
      "23/08/29 00:53:04 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 00:53:08 WARN DAGScheduler: Broadcasting large task binary with size 1212.5 KiB\n",
      "23/08/29 00:53:49 WARN DAGScheduler: Broadcasting large task binary with size 1374.9 KiB\n",
      "23/08/29 00:53:52 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/08/29 00:53:58 WARN DAGScheduler: Broadcasting large task binary with size 1349.5 KiB\n",
      "23/08/29 00:54:30 WARN DAGScheduler: Broadcasting large task binary with size 1508.5 KiB\n",
      "23/08/29 00:55:01 WARN DAGScheduler: Broadcasting large task binary with size 1400.2 KiB\n",
      "23/08/29 00:55:04 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 00:55:08 WARN DAGScheduler: Broadcasting large task binary with size 1200.2 KiB\n",
      "23/08/29 00:55:35 WARN DAGScheduler: Broadcasting large task binary with size 1400.2 KiB\n",
      "23/08/29 00:55:39 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 00:55:43 WARN DAGScheduler: Broadcasting large task binary with size 1200.2 KiB\n",
      "23/08/29 00:56:25 WARN DAGScheduler: Broadcasting large task binary with size 1365.7 KiB\n",
      "23/08/29 00:56:28 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 00:56:34 WARN DAGScheduler: Broadcasting large task binary with size 1328.1 KiB\n",
      "23/08/29 00:57:09 WARN DAGScheduler: Broadcasting large task binary with size 1486.0 KiB\n",
      "23/08/29 00:57:52 WARN DAGScheduler: Broadcasting large task binary with size 1391.5 KiB\n",
      "23/08/29 00:57:58 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 00:58:03 WARN DAGScheduler: Broadcasting large task binary with size 1192.2 KiB\n",
      "23/08/29 00:58:43 WARN DAGScheduler: Broadcasting large task binary with size 1391.5 KiB\n",
      "23/08/29 00:58:48 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 00:58:55 WARN DAGScheduler: Broadcasting large task binary with size 1192.2 KiB\n",
      "23/08/29 00:59:31 WARN DAGScheduler: Broadcasting large task binary with size 1365.5 KiB\n",
      "23/08/29 00:59:35 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 00:59:39 WARN DAGScheduler: Broadcasting large task binary with size 1359.5 KiB\n",
      "23/08/29 01:00:08 WARN DAGScheduler: Broadcasting large task binary with size 1499.4 KiB\n",
      "23/08/29 01:00:36 WARN DAGScheduler: Broadcasting large task binary with size 1387.3 KiB\n",
      "23/08/29 01:00:43 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 01:00:49 WARN DAGScheduler: Broadcasting large task binary with size 1199.1 KiB\n",
      "23/08/29 01:01:21 WARN DAGScheduler: Broadcasting large task binary with size 1387.3 KiB\n",
      "23/08/29 01:01:24 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 01:01:28 WARN DAGScheduler: Broadcasting large task binary with size 1199.1 KiB\n",
      "23/08/29 01:02:03 WARN DAGScheduler: Broadcasting large task binary with size 1373.2 KiB\n",
      "23/08/29 01:02:07 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 01:02:13 WARN DAGScheduler: Broadcasting large task binary with size 1349.4 KiB\n",
      "23/08/29 01:03:00 WARN DAGScheduler: Broadcasting large task binary with size 1454.6 KiB\n",
      "23/08/29 01:03:31 WARN DAGScheduler: Broadcasting large task binary with size 1405.5 KiB\n",
      "23/08/29 01:03:34 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 01:03:38 WARN DAGScheduler: Broadcasting large task binary with size 1201.4 KiB\n",
      "23/08/29 01:04:06 WARN DAGScheduler: Broadcasting large task binary with size 1405.5 KiB\n",
      "23/08/29 01:04:09 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 01:04:13 WARN DAGScheduler: Broadcasting large task binary with size 1201.4 KiB\n",
      "23/08/29 01:04:41 WARN DAGScheduler: Broadcasting large task binary with size 1361.3 KiB\n",
      "23/08/29 01:04:46 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/29 01:04:51 WARN DAGScheduler: Broadcasting large task binary with size 1322.7 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6834133016457417\n"
     ]
    }
   ],
   "source": [
    "cvModel = cv.fit(flights_train)\n",
    "\n",
    "# Average AUC for each parameter combination in grid\n",
    "avg_auc = cvModel.avgMetrics\n",
    "\n",
    "# Average AUC for the best model\n",
    "best_model_auc = max(avg_auc)\n",
    "\n",
    "# What's the optimal paramter value?\n",
    "opt_max_depth = cvModel.bestModel.explainParam('maxDepth')\n",
    "opt_feat_substrat = cvModel.bestModel.explainParam('featureSubsetStrategy')\n",
    "\n",
    "# AUC for best model on test data\n",
    "best_auc = evaluator.evaluate(cvModel.transform(flights_test))\n",
    "print(best_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! Optimized Random Forest > Random Forest > Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing thoughts\n",
    "  \n",
    "Congratulations on completing this course on Machine Learning with Apache Spark. You have covered a lot of ground, reviewing some Machine Learning fundamentals and seeing how they can be applied to large datasets, using Spark for distributed computing.\n",
    "  \n",
    "**Things you've learned**\n",
    "  \n",
    "You learned how to load data into Spark and then perform a variety of operations on those data. Specifically, you learned basic column manipulation on DataFrames, how to deal with text data, bucketing continuous data and one-hot encoding categorical data. You then delved into two types of classifiers, Decision Trees and Logistic Regression, in the process building a robust spam classifier. You also learned about partitioning your data and how to use testing data and a selection of metrics to evaluate a model. Next you learned about regression, starting with a simple linear regression model and progressing to penalized regression, which allowed you to build a model using only the most relevant predictors. You learned about pipelines and how they can make your Spark code cleaner and easier to maintain. This led naturally into using cross-validation and grid search to derive more robust model metrics and use them to select good model parameters. Finally you encountered two forms of ensemble models.\n",
    "\n",
    "**Learning more**\n",
    "  \n",
    "Of course, there are many topics that were not covered in this course. If you want to dig deeper then consult the excellent and extensive online documentation. Importantly you can find instructions for setting up and securing a Spark cluster.\n",
    "  \n",
    "**Congratulations!**\n",
    "  \n",
    "Now go and use what you've learned to solve challenging and interesting big data problems in the real world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
