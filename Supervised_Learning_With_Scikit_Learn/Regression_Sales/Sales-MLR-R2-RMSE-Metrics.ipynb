{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple Linear Regression Machine Learning In Python\n",
    "\n",
    "# Demostration of MLR, train/test split, creating a prediction, evaluating R2 and RMSE of model.\n",
    "\n",
    "# y = a1x1 + a2x2 + a3x3 + ... + anxn + b\n",
    "# y = target\n",
    "# x = single feature\n",
    "# a,b = parameters/coefficients of the model - slope,intercept\n",
    "\n",
    "# How do we choose a and b?\n",
    "# - Define an error function for any given line\n",
    "# - Choose the line that minimizes the error function\n",
    "# Error function = lost function = cost function\n",
    "\n",
    "# __________Terms__________\n",
    "# Residual:                     is the difference between the expected results from a model and the true values from data.\n",
    "# Variance:                     is the variability in the expected results (predictions) of a given data point between different runs of the model.\n",
    "# R-squared:                    is the absolute amount of variation as a proportion of total variation. quantifies the amount of variance in the target variable that is explained by the features. Ranges from 0 to 1, 0=low, 1=high\n",
    "# Mean Squared Error (MSE):     measures the amount of error in statistical models. It assesses the average squared difference between the observed and predicted values. When a model has no error, the MSE equals zero. As model error increases, its value increases.\n",
    "# Root Mean Squared Error(RMSE):Root mean square error or root mean square deviation is one of the most commonly used measures for evaluating the quality of predictions. It shows how far predictions fall from measured true values using Euclidean distance.\n",
    "# RSS:                          residual sum of squares, The residual sum of squares (RSS) is the absolute amount of explained variation.\n",
    "# Ordinary Least Squares(OLS):  Goal is to Minimize RSS. A Common technique for estimating coefficients of linear regression equations which describe the relationship\n",
    "#                               between one or more independent quantitative variables and a dependent variable (simple or multiple linear regression).\n",
    "#                               OLS estimators minimize the sum of the squared errors (a difference between observed values and predicted values).\n",
    "# - Advantages of OLS:          OLS is the most efficient linear regression estimator when the assumptions hold true. \n",
    "#                               Another benefit of satisfying these assumptions is that as the sample size increases to infinity, the coefficient estimates converge on the actual population parameters.\n",
    "# - Disadvantages of OLS:       As with OLS, a large data set is necessary in order to obtain reliable results. \n",
    "#                               The regression results are sensitive to functional form if the error term is not adequately interpreted, which can lead to widely varying conclusions depending on how the regression is initially set up.\n",
    "\n",
    "\n",
    "# pip3 install pandas\n",
    "# pip3 install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Importing the 'advertising_and_sales_clean.csv' dataset as a pandas dataframe\n",
    "sales_df = pd.read_csv('../../_datasets/advertising_and_sales_clean.csv')\n",
    "\n",
    "# Removing column \"influencer\"\n",
    "sales_df = sales_df.drop(\"influencer\", axis=1)\n",
    "\n",
    "# Create X and y arrays, X represents the features, y represents the target.\n",
    "X = sales_df.drop('sales', axis=1).values\n",
    "y = sales_df['sales'].values\n",
    "\n",
    "# Creating splits on df\n",
    "# test_size parameter states we are reserving 70% for training and 30% for testing.\n",
    "# random_state parameter sets a seed.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate the model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [53176.66154234 70996.19873235], Actual Values: [55261.28 67574.9 ]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Display the first 2 predictions, as well as the actual values.\n",
    "# .format() is placing the passed values into the respective {}'s.\n",
    "print(\"Predictions: {}, Actual Values: {}\".format(y_pred[:2], y_test[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9990152104759368\n",
      "RMSE: 2944.433199600101\n"
     ]
    }
   ],
   "source": [
    "# Compute R-squared\n",
    "r_squared = reg.score(X_test, y_test)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"R^2: {}\".format(r_squared))\n",
    "print(\"RMSE: {}\".format(rmse))\n",
    "\n",
    "# At 0.9990152104759368 R^2, the features explain 99% of the variance in sales values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52d43516e08ba44a91236334f3ff506a57085b07359b42e8a57478a41bcad1ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
