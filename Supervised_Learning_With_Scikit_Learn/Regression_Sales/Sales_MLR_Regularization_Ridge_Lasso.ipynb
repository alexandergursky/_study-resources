{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Linear Regression Machine Learning In Python\n",
    "\n",
    "# Demostration of MLR, cross-validation, evaluating cross-validation.\n",
    "\n",
    "# y = a1x1 + a2x2 + a3x3 + ... + anxn + b\n",
    "# y = target\n",
    "# x = single feature\n",
    "# a,b = parameters/coefficients of the model - slope,intercept\n",
    "\n",
    "# How do we choose a and b?\n",
    "# - Define an error function for any given line\n",
    "# - Choose the line that minimizes the error function\n",
    "# Error function = lost function = cost function\n",
    "# Regression minimizes a loss function to choose a coefficient 'a', for each feature and the intercept 'b'. If we allow these coefficients to become too large = overfitting.\n",
    "\n",
    "\n",
    "# __________Terms__________\n",
    "# Residual:                     is the difference between the expected results from a model and the true values from data.\n",
    "# Variance:                     is the variability in the expected results (predictions) of a given data point between different runs of the model.\n",
    "# R-squared:                    is the absolute amount of variation as a proportion of total variation. quantifies the amount of variance in the target variable that is explained by the features. Ranges from 0 to 1, 0=low, 1=high\n",
    "# Mean Squared Error (MSE):     measures the amount of error in statistical models. It assesses the average squared difference between the observed and predicted values. When a model has no error, the MSE equals zero. As model error increases, its value increases.\n",
    "# Root Mean Squared Error(RMSE):Root mean square error or root mean square deviation is one of the most commonly used measures for evaluating the quality of predictions. It shows how far predictions fall from measured true values using Euclidean distance.\n",
    "# RSS:                          residual sum of squares, The residual sum of squares (RSS) is the absolute amount of explained variation.\n",
    "# Ordinary Least Squares(OLS):  Goal is to Minimize RSS. A Common technique for estimating coefficients of linear regression equations which describe the relationship\n",
    "#                               between one or more independent quantitative variables and a dependent variable (simple or multiple linear regression).\n",
    "#                               OLS estimators minimize the sum of the squared errors (a difference between observed values and predicted values).\n",
    "# - Advantages of OLS:          OLS is the most efficient linear regression estimator when the assumptions hold true. \n",
    "#                               Another benefit of satisfying these assumptions is that as the sample size increases to infinity, the coefficient estimates converge on the actual population parameters.\n",
    "# - Disadvantages of OLS:       As with OLS, a large data set is necessary in order to obtain reliable results. \n",
    "#                               The regression results are sensitive to functional form if the error term is not adequately interpreted, which can lead to widely varying conclusions depending on how the regression is initially set up.\n",
    "# Cross Fold Validation:        Folds the training data over in nth folds. In 5-fold the data would be spliced in 5ths, then 4 would be used to compare on the 5th, iterates 5 times to use each block/fold as a validation. More folds = higher computational expense.\n",
    "#                               Cross-validation is a vital approach to evaluating a model. It maximizes the amount of data that is available to the model, as the model is not only trained but also tested on all of the available data.\n",
    "#                               By using cross-validation, we can see how performance varies depending on how the data is split.\n",
    "# Hyperparameter:               Variable used to to optimize model parameters.\n",
    "# Regularization:               Penalizes large coefficients.\n",
    "# - Ridge Regression:           Ridge penalizes large positive or negative coefficients. contains the hyperprameter Alpha which is simular to Kappa in KNN. Alpha controls model complexity.\n",
    "#                               When Alpha = 0 we are preforming OLS (Can lead to overfitting). A very high Alpha can lead extreme penalization of coefficients ie. underfitting.\n",
    "# - Lasso Regression:           Can be used to select feature importance, as it actually shrinks the coefficients of least importance to 0. The features not reduced will be selected by Lasso.\n",
    "\n",
    "\n",
    "# pip3 install pandas\n",
    "# pip3 install scikit-learn\n",
    "# pip3 install matplotlib\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing the 'advertising_and_sales_clean.csv' dataset as a pandas dataframe\n",
    "sales_df = pd.read_csv('/Users/alexandergursky/Local_Repository/Datasets/Structured/CSV/advertising_and_sales_clean.csv')\n",
    "\n",
    "# Removing column \"influencer\"\n",
    "sales_df = sales_df.drop(\"influencer\", axis=1)\n",
    "\n",
    "# Create X and y arrays, X represents the features, y represents the target.\n",
    "X = sales_df.drop('sales', axis=1).values\n",
    "y = sales_df['sales'].values\n",
    "\n",
    "# Creating splits on df\n",
    "# test_size parameter states we are reserving 70% for training and 30% for testing.\n",
    "# random_state parameter sets a seed.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9990152104759369, 0.9990152104759373, 0.9990152104759419, 0.9990152104759871, 0.9990152104764387, 0.9990152104809561]\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "\n",
    "# Creating Alphas\n",
    "alphas = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
    "\n",
    "# Creating empty list so that we can compare the alphas and determine which one we should use.\n",
    "ridge_scores = []\n",
    "for alpha in alphas:\n",
    "  \n",
    "  # Instantiate a Ridge regression model\n",
    "  ridge = Ridge(alpha=alpha)\n",
    "  \n",
    "  # Fit the data\n",
    "  ridge.fit(X_train, y_train)\n",
    "  \n",
    "  # Obtain R-squared and append it to our list\n",
    "  score = ridge.score(X_test,y_test)\n",
    "  ridge_scores.append(score)\n",
    "\n",
    "# Display our R2 scores for each Alpha\n",
    "print(ridge_scores)\n",
    "\n",
    "# Terminal output\n",
    "# [0.9990152104759369, 0.9990152104759373, 0.9990152104759419, 0.9990152104759871, 0.9990152104764387, 0.9990152104809561]\n",
    "\n",
    "# The scores don't appear to change much as alpha increases, which is indicative of how well the features explain the variance in the target.\n",
    "# Even by heavily penalizing large coefficients, underfitting does not occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.56256962 -0.00397035  0.00496385]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lasso Regression for Feature Selection\n",
    "\n",
    "\n",
    "# Aquire Column names\n",
    "sales_columns = sales_df.drop(\"sales\", axis=1).columns\n",
    "\n",
    "# Instantiate a lasso regression model\n",
    "lasso = Lasso(alpha=0.3)\n",
    "\n",
    "# Fit the model to the data\n",
    "fit_lasso = lasso.fit(X, y)\n",
    "\n",
    "# Compute and print the coefficients\n",
    "lasso_coef = fit_lasso.coef_\n",
    "print(lasso_coef)\n",
    "plt.bar(sales_columns, lasso_coef)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# The figure makes it clear that expenditure on TV \n",
    "# advertising is the most important feature in the dataset to predict sales values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52d43516e08ba44a91236334f3ff506a57085b07359b42e8a57478a41bcad1ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
