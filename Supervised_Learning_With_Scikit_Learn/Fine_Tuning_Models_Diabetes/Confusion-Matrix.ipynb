{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pregnancies     glucose   diastolic     triceps     insulin  \\\n",
      "count   768.000000  768.000000  768.000000  768.000000  768.000000   \n",
      "mean      3.845052  120.894531   69.105469   20.536458   79.799479   \n",
      "std       3.369578   31.972618   19.355807   15.952218  115.244002   \n",
      "min       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%       1.000000   99.000000   62.000000    0.000000    0.000000   \n",
      "50%       3.000000  117.000000   72.000000   23.000000   30.500000   \n",
      "75%       6.000000  140.250000   80.000000   32.000000  127.250000   \n",
      "max      17.000000  199.000000  122.000000   99.000000  846.000000   \n",
      "\n",
      "              bmi         dpf         age    diabetes  \n",
      "count  768.000000  768.000000  768.000000  768.000000  \n",
      "mean    31.992578    0.471876   33.240885    0.348958  \n",
      "std      7.884160    0.331329   11.760232    0.476951  \n",
      "min      0.000000    0.078000   21.000000    0.000000  \n",
      "25%     27.300000    0.243750   24.000000    0.000000  \n",
      "50%     32.000000    0.372500   29.000000    0.000000  \n",
      "75%     36.600000    0.626250   41.000000    1.000000  \n",
      "max     67.100000    2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Understanding Confusion Matrix's and Classification Reports\n",
    "\n",
    "\n",
    "# __________Terms__________\n",
    "# Accuracy: This measures the proportion of correctly classified instances over the total number of instances.\n",
    "# Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# Precision: This measures the proportion of correctly classified positive instances over the total number of positive predictions.\n",
    "# Precision = TP / (TP + FP)\n",
    "\n",
    "# Recall (Sensitivity): This measures the proportion of correctly classified positive instances over the total number of actual positive instances.\n",
    "# Recall = TP / (TP + FN)\n",
    "\n",
    "# Specificity: This measures the proportion of true negative instances that are correctly identified as negative by the model. It is also known as the true negative rate (TNR).\n",
    "# Specificity = TN / (TN + FP)\n",
    "\n",
    "# F1 Score: This is a harmonic mean of precision and recall, which balances the trade-off between them.\n",
    "# F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "# ROC Curve: Receiver Operating Characteristic (ROC) Curve is a graphical representation of the performance of a binary classifier. The ROC curve plots the true positive rate (sensitivity) against the false positive rate (1-specificity) at various threshold settings.\n",
    "# AUC: Area Under the ROC Curve (AUC) is a measure of the overall performance of a binary classifier.\n",
    "\n",
    "\n",
    "# Importing requirements\n",
    "# pip3 install pandas\n",
    "# pip3 install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Loading the dataset\n",
    "diabetes_df = pd.read_csv('../../_datasets/diabetes_clean.csv')\n",
    "\n",
    "# Displaying statistics\n",
    "print(diabetes_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   pregnancies  768 non-null    int64  \n",
      " 1   glucose      768 non-null    int64  \n",
      " 2   diastolic    768 non-null    int64  \n",
      " 3   triceps      768 non-null    int64  \n",
      " 4   insulin      768 non-null    int64  \n",
      " 5   bmi          768 non-null    float64\n",
      " 6   dpf          768 non-null    float64\n",
      " 7   age          768 non-null    int64  \n",
      " 8   diabetes     768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Displaying more information\n",
    "print(diabetes_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating features and target\n",
    "\n",
    "X = diabetes_df.drop('diabetes',axis=1).values\n",
    "y = diabetes_df['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating | splitting | fitting KNN model\n",
    "\n",
    "# Instanciate KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Splitting model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.4, random_state=42)\n",
    "\n",
    "# Train model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on held out features\n",
    "y_pred = knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[256  43]\n",
      " [102  60]]\n"
     ]
    }
   ],
   "source": [
    "# Generate Confusion Matrix\n",
    "\n",
    "# Actual on column, predicted on row\n",
    "# Confusion Matrix displays [[--,-+],\n",
    "#                           [+-,++]]\n",
    "\n",
    "# Predicted / Actual | Negative | Positive\n",
    "# Negative           | TN       | FN\n",
    "# Positive           | FP       | TP\n",
    "\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78       299\n",
      "           1       0.58      0.37      0.45       162\n",
      "\n",
      "    accuracy                           0.69       461\n",
      "   macro avg       0.65      0.61      0.62       461\n",
      "weighted avg       0.67      0.69      0.66       461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generating Classification Report\n",
    "\n",
    "# Tells metrics for each class \n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52d43516e08ba44a91236334f3ff506a57085b07359b42e8a57478a41bcad1ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
