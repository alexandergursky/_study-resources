{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifiers: The Coefficients\n",
    "The conceptual framework behind logistic regression and SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install numpy\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(3)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y = np.arange(3, 6)\n",
    "print(y)\n",
    "print(y.shape)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  4 10]\n",
      "[0 3 6]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Displaying Dot Product\n",
    "print(x*y)\n",
    "print(x*y.shape)\n",
    "print(type(x*y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "()\n",
      "<class 'numpy.int64'>\n",
      "\n",
      "\n",
      "14\n",
      "()\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "# Displaying Dot Product Summation\n",
    "print(np.sum(x*y))\n",
    "print(np.sum(x*y).shape)\n",
    "print(type(np.sum(x*y)))\n",
    "\n",
    "# Creating new line to demostrate the 2 diffrent ways\n",
    "# that Dot Product summation can be shown\n",
    "print('\\n')\n",
    "\n",
    "# Displaying alternative method\n",
    "# x@y is called the dot product of x and y\n",
    "print(x@y)\n",
    "print((x@y).shape)\n",
    "print(type(x@y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classifier Prediction\n",
    "- Written as: raw model output = coeficients (dot) features + intercept\n",
    "- Linear classifier prediction: compute  raw model output, check the **sign**\n",
    "  - If positive, predict one class\n",
    "  - If negative, predict the other class\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions\n",
    "The loss function is a penalty score that tells us how well (or, to be precise, how poorly) the model is doing on the training data. We can think of the \"fit\" function as running code that minimizes the loss. Note that the score function provided by scikit-learn isn't necessarily the same thing as the loss function. The loss is used to fit the model on the data, and the score is used to see how well we're doing. It's intuitive that these would be the same, and they often are, but you should be aware that this isn't guaranteed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minimizing a loss\n",
    "# pip3 install scipy\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "minimize(np.square, 0).x\n",
    "\n",
    "# It's correct because something squared can only be zero or more, \n",
    "# thus, its smallest possible value is attained when x=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.88846401e-08])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another example of minimizing a loss\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "minimize(np.square, 2).x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
