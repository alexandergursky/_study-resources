{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a \"fake news\" classifier\n",
    "  \n",
    "You'll apply the basics of what you've learned along with some supervised machine learning to build a \"fake news\" detector. You'll begin by learning the basics of supervised machine learning, and then move forward by choosing a few important features and testing ideas to identify and classify fake news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                  # Numerical Python:         Arrays and linear algebra\n",
    "import pandas as pd                 # Panel Datasets:           Dataset manipulation\n",
    "import matplotlib.pyplot as plt     # MATLAB Plotting Library:  Visualizations\n",
    "import seaborn as sns               # Seaborn:                  Visualizations\n",
    "import re                           # Regular Expressions:      Text manipulation\n",
    "from pprint import pprint           # Pretty Print:             Advanced printing operations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying fake news using supervised learning with NLP\n",
    "  \n",
    "In this video, we'll be learning about supervised machine learning with NLP. Throughout this chapter you will be using the skills and ideas applied to classifying fake news.\n",
    "  \n",
    "**What is supervised learning?**\n",
    "  \n",
    "Supervised learning is a form of machine learning where you are given or create training data. This data has a label or outcome which you want the model or algorithm to learn. One common problem used as a good example of introductory machine learning is the Fischer's iris data; we have a few example rows of it here. The data has several features: Sepal Length and width and Petal length and width. The label we want to learn and predict is the species. This is a classification problem, so you want to be able to classify or categorize some data based on what you already know or have learned. Our goal is to use the dataset to make intelligent hypotheses about the species based on the geometric features.\n",
    "  \n",
    "<img src='../_images/supervised-learning-nlp-example.png' alt='img' width='540'>\n",
    "  \n",
    "**Supervised learning with NLP**\n",
    "  \n",
    "But instead of using geometric features like the Iris dataset, we need to use language. To help create features and train a model, we will use `Scikit-learn`, a powerful open-source library. One of the ways you can create supervised learning data from text is by using bag of words models or TFIDF as features.\n",
    "  \n",
    "**Supervised learning with NLP**  \n",
    "  \n",
    "- Need to use language instead of geometric features\n",
    "- Use bag-of-words models or tf-idf features\n",
    "  \n",
    "**IMDB Movie Dataset**\n",
    "  \n",
    "Let's say I have a dataset full of movie plots and genres from the IMDB database, as shown in this chart. I've separated the action and sci-fi movies, removing any movies labeled both action and scifi. I want to predict whether a movie is action or sci-fi based on the plot summary. The dataset we've extracted has categorical features generated using some preprocessing. We can see the plot summary, and the sci-fi and action columns. You can also see the Sci-Fi column, which is 1 for movies that are scifi and 0 for movies that are action. The Action column is the inverse of the Sci-Fi column.\n",
    "  \n",
    "<img src='../_images/supervised-learning-nlp-example1.png' alt='img' width='540'>\n",
    "  \n",
    "**Supervised learning steps**\n",
    "  \n",
    "In the next video, we'll use `scikit-learn` to predict a movie's genre from its plot. But first, let's review the supervised learning process as a whole. To begin, we collect and preprocess our data. Then, we determine a label - this is what we want the model to learn, in our case, the genre of the movie. We can split our data into training and testing datasets, keeping them separate so we can build our model using only the training data. The test data remains unseen so we can test how well our model performs after it is trained. This is an essential part of Supervised Learning! We also need to extract features from the text to predict the label. We will use a bagof words vectorizer built into `scikit-learn` to do so. After the model is trained, we can then test it using the test dataset. There are also other methods to evaluate model performance, such as `KFold` cross validation.\n",
    "  \n",
    "**Supervised learning steps**\n",
    "  \n",
    "- Collect and preprocess our data\n",
    "- Determine a label\n",
    "- Split data into training and test sets\n",
    "- Extract features from the text to help predict the label\n",
    "- Evaluate trained model using test set\n",
    "  \n",
    "**Let's practice!**\n",
    "  \n",
    "Let's review some of the supervised learning steps, like splitting testing and training data before applying it to our movie plot data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which possible features?\n",
    "  \n",
    "Which of the following are possible features for a text classification problem?\n",
    "  \n",
    "Possible Answers\n",
    "  \n",
    "- [ ] Number of words in a document.\n",
    "- [ ] Specific named entities.\n",
    "- [ ] Language.\n",
    "- [x] All of the above.\n",
    "  \n",
    "Correct!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing\n",
    "  \n",
    "What datasets are needed for supervised learning?\n",
    "  \n",
    "Possible Answers\n",
    "  \n",
    "- [ ] Training data.\n",
    "- [ ] Testing data.\n",
    "- [x] Both training and testing data.\n",
    "- [ ] A label or outcome.\n",
    "  \n",
    "Correct!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building word count vectors with scikit-learn\n",
    "  \n",
    "In this video, we'll build our first scikit learn vectors from the movie plot and genre dataset.\n",
    "  \n",
    "**Predicting movie genre**\n",
    "  \n",
    "We have a dataset full of movie plots and what genre the movie is -- either action or sci-fi. We want to create bag of words vectors for these movie plots to see if we can predict the genre based on the words used in the plot summary.\n",
    "  \n",
    "<img src='../_images/supervised-learning-nlp-example2.png' alt='img' width='540'>\n",
    "  \n",
    "**Count Vectorizer with Python**\n",
    "  \n",
    "To do so, we first need to import some necessary tools from Scikit-learn. Once the data is loaded, we can create `y` which traditionally refers to the labels or outcome you want the model to learn. We can use the Sci-Fi column which has 1 if the movie is Sci-Fi and 0 if it is Action. Then, scikit learn's `train_test_split()` function can be used to split the dataframe into training and testing data. This method will split the features which is the plot summary or column PLOT and the labels (`y`) based on a given `test_size=` such as 0.33, representing 33 percent. I have also set `random_state=` so we have a repeatable result, it operates similar to setting a random seed and ensures I get the same results when I run the code again. The function will take 33% of rows to be marked as test data, and remove them from the training data. The test data is later used to see what my model has learned. The resulting data from `train_test_split()` are training data (as `X_train`) and training labels (as `y_train`) and testing data as `X_test` and testing labels as `y_test`. Next, we create a `CountVectorizer` object which turns my text into bag-of-words vectors similar to a `Gensim` corpus, it will also remove English stop words from the movie plot summaries as a preprocessing step by passing the argument `stop_words='english'`. \n",
    "  \n",
    "Each token now acts as a feature for the machine learning classification problem, just like the flower measurements in the iris data set. We can then call `.fit_transform()` on the training data to create the bag-of-words vectors. `.fit_transform()` is a handy shortcut which will call the model's fit and then transform methods; which here generates a mapping of words with IDs and vectors representing how many times each word appears in the plot. \n",
    "  \n",
    "`.fit_transform()` operates differently for each model, but generally fit will find parameters or norms in the data and transform will apply the model's underlying algorithm or approximation -- similar to preprocessing but with a specific use case in mind. \n",
    "  \n",
    "For the `CountVectorizer` class, `.fit_transform()` will create the bagofwords dictionary and vectors for each document using the training data. After calling `.fit_transform()` on the training data, we call transform on the test data to create bag of words vectors using the same dictionary. The training and test vectors need to use a consistent set of words, so the trained model can understand the test input. If we don't have much data, there can be an issue with words in the test set which don't appear in the training data. This will throw an error, so you will need to either add more training data or remove the unknown words from the test dataset. In only a few lines of Python, we have transformed text into bag-of-words vectors and generated test and training datasets. Scikit-learn is a great aid in helping make NLP machine learning simple and accessible.\n",
    "  \n",
    "<img src='../_images/supervised-learning-nlp-example3.png' alt='img' width='540'>\n",
    "  \n",
    "**Let's practice!**\n",
    "  \n",
    "Now it's your turn to create some scikitlearn vectors!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `CountVectorizer` for text classification\n",
    "  \n",
    "It's time to begin building your text classifier! The data has been loaded into a DataFrame called df. Explore it in the IPython Shell to investigate what columns you can use. The `.head()` method is particularly informative.\n",
    "  \n",
    "In this exercise, you'll use pandas alongside scikit-learn to create a sparse text vectorizer you can use to train and test a simple supervised model. To begin, you'll set up a `CountVectorizer` and investigate some of its features.\n",
    "  \n",
    "1. Import `CountVectorizer` `from sklearn.feature_extraction.text` and `train_test_split` `from sklearn.model_selection`.\n",
    "2. Create a Series `y` to use for the labels by assigning the `.label` attribute of df to `y`.\n",
    "3. Using df[\"text\"] (features) and `y` (labels), create training and test sets using `train_test_split()`. Use a `test_size=` of 0.33 and a `random_state=` of 53.\n",
    "4. Create a `CountVectorizer` object called `count_vectorizer`. Ensure you specify the keyword argument `stop_words=\"english\"` so that stop words are removed.\n",
    "5. Fit and transform the training data `X_train` using the `.fit_transform()` method of your `CountVectorizer` object. Do the same with the test data `X_test`, except using the `.transform()` method.\n",
    "6. Print the first 10 features of the `count_vectorizer` using its `.get_feature_names()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../_datasets/fake_or_real_news.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '0000' '00000031' '000035' '00006' '0001' '0001pt' '000ft'\n",
      " '000km']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Create a series to store the labels: y\n",
    "y = df.label\n",
    "\n",
    "# Create training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.33, random_state=53)\n",
    "\n",
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Transform the training data using only the 'text' column values: count_train\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using only the 'text' column values: count_test\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features of the count_vectorizer\n",
    "print(count_vectorizer.get_feature_names_out()[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TfidfVectorizer` for text classification\n",
    "  \n",
    "Similar to the sparse `CountVectorizer` created in the previous exercise, you'll work on creating tf-idf vectors for your documents. You'll set up a `TfidfVectorizer` and investigate some of its features.\n",
    "  \n",
    "In this exercise, you'll use `pandas` and `sklearn` along with the same `X_train`, `y_train` and `X_test`, `y_test` DataFrames and Series you created in the last exercise.\n",
    "  \n",
    "1. Import `TfidfVectorizer` `from sklearn.feature_extraction.text`.\n",
    "2. Create a `TfidfVectorizer` object called `tfidf_vectorizer`. When doing so, specify the keyword arguments `stop_words=\"english\"` and `max_df=0.7`.\n",
    "3. Fit and transform the training data.\n",
    "4. Transform the test data.\n",
    "5. Print the first 10 features of `tfidf_vectorizer`.\n",
    "6. Print the first 5 vectors of the tfidf training data using slicing on the `.A` (or array) attribute of `tfidf_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '0000' '00000031' '000035' '00006' '0001' '0001pt' '000ft'\n",
      " '000km']\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)  # Max_DocumentFrequency\n",
    "\n",
    "# Transform the training data: tfidf_train\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# transform the test data: tfidf_test\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names_out()[:10])\n",
    "\n",
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train.A[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct!\n",
    "  \n",
    "The code output in the example, what I did was the same and correct, just wanted to add this in as it shows some more information about the display.\n",
    "  \n",
    "```python\n",
    "<script.py> output:\n",
    "    ['00', '000', '001', '008s', '00am', '00pm', '01', '01am', '02', '024']\n",
    "    [[0.         0.01928563 0.         ... 0.         0.         0.        ]\n",
    "     [0.         0.         0.         ... 0.         0.         0.        ]\n",
    "     [0.         0.02895055 0.         ... 0.         0.         0.        ]\n",
    "     [0.         0.03056734 0.         ... 0.         0.         0.        ]\n",
    "     [0.         0.         0.         ... 0.         0.         0.        ]]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the vectors\n",
    "  \n",
    "To get a better idea of how the vectors work, you'll investigate them by converting them into `pandas` DataFrames.\n",
    "\n",
    "Here, you'll use the same data structures you created in the previous two exercises (`count_train`, `count_vectorizer`, `tfidf_train`, `tfidf_vectorizer`) as well as`pandas`, which is imported `as pd`.\n",
    "  \n",
    "1. Create the DataFrames `count_df` and `tfidf_df` by using `pd.DataFrame()` and specifying the values as the first argument and the columns (or features) as the second argument.\n",
    "- The values can be accessed by using the `.A` attribute of, respectively, `count_train` and `tfidf_train`.\n",
    "- The columns can be accessed using the `.get_feature_names_out()` methods of `count_vectorizer` and `tfidf_vectorizer`.\n",
    "2. Print the head of each DataFrame to investigate their structure. This has been done for you.\n",
    "3. Test if the column names are the same for each DataFrame by creating a new object called `difference` to see the difference between the columns that `count_df` has from `tfidf_df`. Columns can be accessed using the `.columns` attribute of a DataFrame. Subtract the set of `tfidf_df.columns` from the set of `count_df.columns`.\n",
    "4. Test if the two DataFrames are equivalent by using the `.equals()` method on `count_df` with `tfidf_df` as the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4244, 56922)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000031</th>\n",
       "      <th>000035</th>\n",
       "      <th>00006</th>\n",
       "      <th>0001</th>\n",
       "      <th>0001pt</th>\n",
       "      <th>000ft</th>\n",
       "      <th>000km</th>\n",
       "      <th>...</th>\n",
       "      <th>حلب</th>\n",
       "      <th>عربي</th>\n",
       "      <th>عن</th>\n",
       "      <th>لم</th>\n",
       "      <th>ما</th>\n",
       "      <th>محاولات</th>\n",
       "      <th>من</th>\n",
       "      <th>هذا</th>\n",
       "      <th>والمرضى</th>\n",
       "      <th>ยงade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56922 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n",
       "0   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "1   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "2   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "3   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "4   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "\n",
       "   حلب  عربي  عن  لم  ما  محاولات  من  هذا  والمرضى  ยงade  \n",
       "0    0     0   0   0   0        0   0    0        0      0  \n",
       "1    0     0   0   0   0        0   0    0        0      0  \n",
       "2    0     0   0   0   0        0   0    0        0      0  \n",
       "3    0     0   0   0   0        0   0    0        0      0  \n",
       "4    0     0   0   0   0        0   0    0        0      0  \n",
       "\n",
       "[5 rows x 56922 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the CountVectorizer DataFrame: count_df\n",
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Print the head of count_df\n",
    "print(count_df.shape)\n",
    "count_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4244, 56922)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000031</th>\n",
       "      <th>000035</th>\n",
       "      <th>00006</th>\n",
       "      <th>0001</th>\n",
       "      <th>0001pt</th>\n",
       "      <th>000ft</th>\n",
       "      <th>000km</th>\n",
       "      <th>...</th>\n",
       "      <th>حلب</th>\n",
       "      <th>عربي</th>\n",
       "      <th>عن</th>\n",
       "      <th>لم</th>\n",
       "      <th>ما</th>\n",
       "      <th>محاولات</th>\n",
       "      <th>من</th>\n",
       "      <th>هذا</th>\n",
       "      <th>والمرضى</th>\n",
       "      <th>ยงade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56922 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n",
       "0  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
       "1  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
       "2  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
       "3  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
       "4  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
       "\n",
       "   حلب  عربي   عن   لم   ما  محاولات   من  هذا  والمرضى  ยงade  \n",
       "0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "1  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "2  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "3  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "4  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "\n",
       "[5 rows x 56922 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the head of tfidf_df\n",
    "print(tfidf_df.shape)\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference in columns: difference\n",
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "print(difference)\n",
    "\n",
    "# Check whether the DataFrame are equal\n",
    "print(count_df.equals(tfidf_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: If executing the code snippet returns an output of `set()`, it means that there are no differing columns between `count_df.columns` and `tfidf_df.columns`. In other words, both `count_df` and `tfidf_df` have the exact same columns.\n",
    "  \n",
    "NOTE: If executing `print(count_df.equals(tfidf_df))` returns `False`, it means that the two DataFrames, `count_df` and `tfidf_df`, are not equal.\n",
    "  \n",
    "The `equals()` method in Pandas is used to check if two DataFrames are element-wise equal. It compares the values and column labels of the two DataFrames and returns `True` if they are the same, and `False` otherwise.\n",
    "  \n",
    "Possible reasons for `False` as the output could be:\n",
    "  \n",
    "1. **Different values**: The DataFrames have different values in at least one cell or multiple cells. Even a single difference in value will make the two DataFrames unequal.\n",
    "2. **Different column labels**: The DataFrames have different column labels, meaning they have different column names or the columns are in a different order.\n",
    "3. **Different indices**: The DataFrames have different indices, indicating that the rows are not aligned or ordered in the same way.\n",
    "  \n",
    "To identify the specific differences between the two DataFrames, you can compare them visually by printing their contents or use other methods such as `diff()` or `compare()` provided by Pandas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing a classification model with scikit-learn\n",
    "  \n",
    "In this video, we'll use the features we have extracted to train and test a supervised classification model.\n",
    "  \n",
    "**Naive Bayes classifier**\n",
    "  \n",
    "A Naive Bayes model is commonly used for testing NLP classification problems because of its basis in probability. Naive bayes algorithm uses probability, attempting to answer the question if given a particular piece of data, how likely is a particular outcome? For example, thinking back to our movie genres dataset -- If the plot has a spaceship, how likely is it that the movie is Sci-Fi? And given a Spaceship and an alien how likely NOW is it a sci-fi movie? Each word acts as a feature from our `CountVectorizer` helping classify our text using probability. \n",
    "  \n",
    "Naive bayes has been used for text classification problems since the 1960s and continues to be used today despite the growth of many other models, algorithms and neural network architectures. That said, it is not always the best tool for the job, but it is a simple and effective one you will use to build a fake news classifier.\n",
    "  \n",
    "<img src='../_images/training-and-testing-sklearn-classification-models-for-nlp.png' alt='img' width='540'>\n",
    "  \n",
    "**Naive Bayes with scikit-learn**\n",
    "  \n",
    "We'll use scikit learn's naive bayes to take a look at our scifi versus action plot classification problem. Recall the data we're using is simply IMDB plot summaries, and whether the movie is science fiction or action. \n",
    "  \n",
    "First, we import the naive bayes model class, multinomial naive bayes, which works well with count vectorizers as it expects integer inputs. `MultinomialNB` is also used for multiple label classification. This model may not work as well with floats, such as tfidf weighted inputs. \n",
    "  \n",
    "Instead, use support vector machines or even linear models; although I recommend trying Naive Bayes first to determine if it can also work well. We use the `metrics` module to evaluate model performance. We initialize our class and call `.fit()` with the training data. If you recall from the previous video, this will determine the internal parameters based on the dataset. \n",
    "  \n",
    "We pass the training count vectorizer first and the training labels second. After fitting the model, we call `.predict()` with the count vectorizer test data. `.predict()` will use the trained model to predict the label based on the test data vectors. We save the predicted labels in variable pred to test the accuracy. Finally, we test accuracy using `accuracy_score` from the `metrics` module and passing the predicted and test labels. Accuracy for our model means the percentage of correct genre guesses out of total guesses. Our model has about 86% accuracy -- which is pretty good for a first try! You'll be applying the Multinomial Naive Bayes classifier to the fake news dataset in the following exercises.\n",
    "  \n",
    "<img src='../_images/training-and-testing-sklearn-classification-models-for-nlp1.png' alt='img' width='540'>\n",
    "  \n",
    "**Confusion matrix**\n",
    "  \n",
    "To further evaluate our model, we can also check the confusion matrix which shows correct and incorrect labels. The `confusion_matrix` function from the `metrics` module takes the test labels, the predictions and a list of labels. If the label list is not passed, scikit-learn will order them using Python ordering. The confusion matrix is a bit easier to read when we transform it into a table. The first value and last value of the matrix (or the main diagonal of the matrix) show `True` scores, meaning, `True` classification of both action and scifi films based on the plot bag of words vectors. In a confusion matrix, the predicted labels are shown across the top and the true labels are shown down the side. \n",
    "  \n",
    "This confusion matrix shows 864 Sci-Fi movies incorrectly labeled as Action and 563 Action movies incorrectly labeled as Sci-Fi. We can see from the distribution of true positives and negatives that our dataset is a bit skewed, we have many more action films than sci-fi. This could be one reason that our action movies are predicted more accurately.\n",
    "  \n",
    "<img src='../_images/training-and-testing-sklearn-classification-models-for-nlp2.png' alt='img' width='540'>\n",
    "  \n",
    "**Let's practice!**\n",
    "  \n",
    "Now it's your turn to train and test a naive bayes model for the fake news problem!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification models\n",
    "  \n",
    "Which of the below is the most reasonable model to use when training a new supervised model using text vector data?\n",
    "  \n",
    "Possible Answers\n",
    "  \n",
    "- [ ] Random Forests\n",
    "- [x] Naive Bayes\n",
    "- [ ] Linear Regression\n",
    "- [ ] Deep Learning\n",
    "  \n",
    "Correct!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing the \"fake news\" model with `CountVectorizer`\n",
    "  \n",
    "Now it's your turn to train the \"fake news\" model using the features you identified and extracted. In this first exercise you'll train and test a Naive Bayes model using the `CountVectorizer` data.\n",
    "  \n",
    "The training and test sets have been created, and `count_vectorizer`, `count_train`, and `count_test` have been computed.\n",
    "  \n",
    "1. Import the `metrics` module from `sklearn` and `MultinomialNB` `from sklearn.naive_bayes`.\n",
    "2. Instantiate a `MultinomialNB` classifier called `nb_classifier`.\n",
    "3. Fit the classifier to the training data.\n",
    "4. Compute the predicted tags for the test data.\n",
    "5. Calculate and print the accuracy score of the classifier.\n",
    "6. Compute the confusion matrix. To make it easier to read, specify the keyword argument `labels=['FAKE', 'REAL']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.893352462936394\n",
      "[[ 865  143]\n",
      " [  80 1003]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm =confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\n",
    "print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing the \"fake news\" model with `TfidfVectorizer`\n",
    "  \n",
    "Now that you have evaluated the model using the `CountVectorizer`, you'll do the same using the `TfidfVectorizer` with a Naive Bayes model.\n",
    "  \n",
    "The training and test sets have been created, and `tfidf_vectorizer`, `tfidf_train`, and `tfidf_test` have been computed. Additionally, `MultinomialNB` and `metrics` have been imported from, respectively, `sklearn.naive_bayes` and `sklearn`.\n",
    "  \n",
    "1. Instantiate a `MultinomialNB` classifier called `nb_classifier`.\n",
    "2. Fit the classifier to the training data.\n",
    "3. Compute the predicted tags for the test data.\n",
    "4. Calculate and print the accuracy score of the classifier.\n",
    "5. Compute the confusion matrix. As in the previous exercise, specify the keyword argument `labels=['FAKE', 'REAL']` so that the resulting confusion matrix is easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8565279770444764\n",
      "[[ 739  269]\n",
      " [  31 1052]]\n"
     ]
    }
   ],
   "source": [
    "# Create a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(tfidf_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\n",
    "print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct!\n",
    "We can see that `CountVectorizer` preformed better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NLP, complex problems\n",
    "  \n",
    "You've learned so much about Natural Language Processing fundamentals in this course, congratulations! In this video we'll talk more about how complex these problems can be and how to use the skills you have learned to start a longer exploration of working with language in Python. In the exercises, you will apply some extra investigation into your fake news classification model to see if it has really learned what you wanted.\n",
    "  \n",
    "**Translation**\n",
    "  \n",
    "Translation, although it might work well for some languages, still has a long way to go. This tweet by Lupin attempting to translate some legal or bureaucratic text about economics and industry is a pretty funny and also sadly accurate example of when using word vectors between two languages can end poorly. The German text uses words like Nationalökonomie and Wirtschaftswissenschaft but the English text simply says the economics of economics (including economics, economics and so forth) is part of economics. The German text has many different words related to economics and they are all simply closest to the english vector for economics, leading to a hilarious but woefully inaccurate translation.\n",
    "  \n",
    "<img src='../_images/simple-nlp-complex-problems.png' alt='img' width='540'>\n",
    "  \n",
    "**Sentiment analysis**\n",
    "  \n",
    "Sentiment analysis is far from a solved problem. Complex issues like snark or sarcasm, and difficult problems with negation (for example: I liked it BUT it could have been better) make it an open field of research. There is also active research regarding how separate communities use the same words differently. This is a graphic from a project called Social Sent created by a group of researchers at Stanford. The project compares sentiment changes in words over time and from different communities. Here, the authors compare sentiment in word usage between two different reddit communities, 2X which is a woman-centered reddit and sports. The graphic illustrates the SAME word can be used with very different sentiments depending on the communal understanding of the word.\n",
    "  \n",
    "<img src='../_images/simple-nlp-complex-problems1.png' alt='img' width='540'>\n",
    "  \n",
    "**Language biases**\n",
    "  \n",
    "Finally, we must remember language can contain its own prejudices and unfair treatment towards groups. When we then train word vectors on these prejudiced texts, our word vectors will likely reflect those problems. Here, we take a gendered language, like english and translate it to Turkish, a language with no gendered pronouns. When we click to translate it back, we see the genders have switched. This phenomena was studied in a recent article by a Princeton researcher Aylin Caliskan alongside several ethical machine learning researchers. She also gave a talk at the 33rd annual Chaos Computer Club conference in Hamburg, which I can definitely recommend viewing.\n",
    "  \n",
    "<img src='../_images/simple-nlp-complex-problems2.png' alt='img' width='540'>\n",
    "  \n",
    "**Let's practice!**\n",
    "  \n",
    "As we have seen in just a few examples, the field of natural language processing still has plenty of unsolved problems. In fact, our fake news detector is likely one of them! Let's do some investigation into what it has learned to determine if the model will be widely applicable or if the problem is likely more complex than simple word counts."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the model\n",
    "  \n",
    "What are possible next steps you could take to improve the model?\n",
    "  \n",
    "Possible Answers\n",
    "\n",
    "- [ ] Tweaking alpha levels.\n",
    "- [ ] Trying a new classification model.\n",
    "- [ ] Training on a larger dataset.\n",
    "- [ ] Improving text preprocessing.\n",
    "- [x] All of the above.\n",
    "  \n",
    "Indeed!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving your model\n",
    "  \n",
    "Your job in this exercise is to test a few different alpha levels using the Tfidf vectors to determine if there is a better performing combination.\n",
    "  \n",
    "The training and test sets have been created, and `tfidf_vectorizer`, `tfidf_train`, and `tfidf_test` have been computed.\n",
    "  \n",
    "1. Create a list of alphas to try using `np.arange()`. Values should range from 0 to 1 with `step=` of 0.1.\n",
    "2. Create a function `train_and_predict()` that takes in one argument: `alpha`. The function should:\n",
    "- Instantiate a `MultinomialNB` classifier with `alpha=alpha`.\n",
    "- Fit it to the training data.\n",
    "- Compute predictions on the test data.\n",
    "- Compute and return the accuracy score.\n",
    "3. Using a `for` loop, print the `alpha`, score and a newline in between. Use your `train_and_predict()` function to compute the score. Does the score change along with the alpha? What is the best alpha?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0\n",
      "Score:  0.8813964610234337\n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.8976566236250598\n",
      "\n",
      "Alpha:  0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8938307030129125\n",
      "\n",
      "Alpha:  0.30000000000000004\n",
      "Score:  0.8900047824007652\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.8857006217120995\n",
      "\n",
      "Alpha:  0.5\n",
      "Score:  0.8842659014825442\n",
      "\n",
      "Alpha:  0.6000000000000001\n",
      "Score:  0.874701099952176\n",
      "\n",
      "Alpha:  0.7000000000000001\n",
      "Score:  0.8703969392635102\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.8660927785748446\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.8589191774270684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0, 1, 0.1)  # Start, Stop, Step\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    \n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    \n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    \n",
    "    # Compute accuracy: score\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "\n",
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha))\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_alphas = [0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9]\n",
    "\n",
    "plot_scores = [0.8813964610234337, 0.8976566236250598, \n",
    "               0.8938307030129125, 0.8900047824007652, \n",
    "               0.8857006217120995, 0.8842659014825442, \n",
    "               0.874701099952176, 0.8703969392635102, \n",
    "               0.8660927785748446, 0.8589191774270684]\n",
    "\n",
    "plt.plot(plot_alphas, plot_scores)\n",
    "plt.title('Line plot of accuracy scores in relation to alpha values')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting your model\n",
    "  \n",
    "Now that you have built a \"fake news\" classifier, you'll investigate what it has learned. You can map the important vector weights back to actual words using some simple inspection techniques.\n",
    "  \n",
    "You have your well performing tfidf Naive Bayes classifier available as `nb_classifier`, and the vectors as `tfidf_vectorizer`.\n",
    "  \n",
    "1. Save the class labels as `class_labels` by accessing the `.classes_` attribute of `nb_classifier`.\n",
    "2. Extract the features using the `.get_feature_names_out()` method of `tfidf_vectorizer`.\n",
    "3. Create a zipped array of the classifier coefficients with the feature names and sort them by the coefficients. To do this, first use `zip()` with the arguments `nb_classifier.feature_log_prob_[0]` and `feature_names`. Then, use `sorted()` on this.\n",
    "4. Print the top 20 weighted features for the first label of `class_labels` and print the bottom 20 weighted features for the second label of `class_labels`. This has been done for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAKE [(-11.280753302177917, '00000031'), (-11.280753302177917, '00006'), (-11.280753302177917, '000ft'), (-11.280753302177917, '001'), (-11.280753302177917, '002'), (-11.280753302177917, '003'), (-11.280753302177917, '006'), (-11.280753302177917, '008'), (-11.280753302177917, '010'), (-11.280753302177917, '013'), (-11.280753302177917, '025'), (-11.280753302177917, '027'), (-11.280753302177917, '035'), (-11.280753302177917, '037'), (-11.280753302177917, '040'), (-11.280753302177917, '044'), (-11.280753302177917, '048'), (-11.280753302177917, '066'), (-11.280753302177917, '068'), (-11.280753302177917, '075')]\n",
      "REAL [(-8.036772745824807, 'president'), (-8.022187159522364, 'american'), (-8.013319806154513, 'media'), (-8.007761560290644, 'donald'), (-8.006632122322646, 'october'), (-7.989623223030759, 'government'), (-7.929695447721539, 'like'), (-7.922750601304927, 'war'), (-7.915731838943572, 'new'), (-7.908889774759155, 'world'), (-7.885018054191407, 'just'), (-7.758145325115569, 'said'), (-7.7498037548099585, 'russia'), (-7.697669509488481, 'fbi'), (-7.604825769578616, '2016'), (-7.554879292243166, 'election'), (-7.541640806988918, 'people'), (-7.235945549755579, 'hillary'), (-6.923220068888362, 'clinton'), (-6.867377223688766, 'trump')]\n"
     ]
    }
   ],
   "source": [
    "# Get the class labels: class_labels\n",
    "class_labels = nb_classifier.classes_\n",
    "\n",
    "# Extract the features: feature_names\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Zip the feature names together with the coefficient array \n",
    "# and sort by weights: feat_with_weights\n",
    "feat_with_weights = sorted(zip(nb_classifier.feature_log_prob_[0], feature_names))\n",
    "\n",
    "# Print the first class label and the top 20 feat_with_weights entries\n",
    "print(class_labels[0], feat_with_weights[:20])\n",
    "\n",
    "# Print the second class label and the bottom 20 feat_with_weights entries\n",
    "print(class_labels[1], feat_with_weights[-20:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The outputs represent the top 20 features with their corresponding weights for two classes: \"FAKE\" and \"REAL\". Each entry in the list is a tuple containing the weight (logarithm of the probability estimate) and the feature name.\n",
    "  \n",
    "**For the \"FAKE\" class:**\n",
    "  \n",
    "- The feature names are words or terms that have very low probabilities or are less indicative of the \"FAKE\" class based on the model.\n",
    "- The negative weights indicate that these features are more associated with the \"REAL\" class.\n",
    "- The closer the weight is to zero, the more neutral or less informative the feature is in determining the class.\n",
    "  \n",
    "**For the \"REAL\" class:**\n",
    "  \n",
    "- The feature names are words or terms that have higher probabilities or are more indicative of the \"REAL\" class based on the model.\n",
    "- The negative weights indicate that these features are less associated with the \"FAKE\" class.\n",
    "- The weights closer to zero represent less influential or neutral features in classifying as \"REAL\"\n",
    "  \n",
    "It's important to note that the weights represent the model's learned associations between the features and the classes. These associations are based on the training data used to train the model. Interpretation of these weights should be done with caution and in the context of the specific model and dataset.\n",
    "  \n",
    "By examining the top features and their weights, you can gain some insights into the model's learned patterns and which features are more strongly associated with each class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing the models Sentiment Analysis outputs to a dataframe\n",
    "  \n",
    "Shape: `[113844 rows x 3 columns]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Class Label     Weight      Word\n",
      "0             FAKE -11.280753  00000031\n",
      "1             FAKE -11.280753     00006\n",
      "2             FAKE -11.280753     000ft\n",
      "3             FAKE -11.280753       001\n",
      "4             FAKE -11.280753       002\n",
      "...            ...        ...       ...\n",
      "113839        REAL  -7.554879  election\n",
      "113840        REAL  -7.541641    people\n",
      "113841        REAL  -7.235946   hillary\n",
      "113842        REAL  -6.923220   clinton\n",
      "113843        REAL  -6.867377     trump\n",
      "\n",
      "[113844 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get the class labels: class_labels\n",
    "class_labels = nb_classifier.classes_\n",
    "\n",
    "# Extract the features: feature_names\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Zip the feature names together with the logarithm of the probability estimates\n",
    "# and sort by weights: feat_with_weights\n",
    "feat_with_weights = sorted(zip(nb_classifier.feature_log_prob_[0], feature_names))\n",
    "\n",
    "# Create a list of tuples for the first class label\n",
    "class_0_entries = [(class_labels[0], weight, feature) for weight, feature in feat_with_weights]\n",
    "\n",
    "# Create a list of tuples for the second class label\n",
    "class_1_entries = [(class_labels[1], weight, feature) for weight, feature in feat_with_weights]\n",
    "\n",
    "# Combine the entries for both class labels\n",
    "combined_entries = class_0_entries + class_1_entries\n",
    "\n",
    "# Create a DataFrame from the combined entries\n",
    "df = pd.DataFrame(combined_entries, columns=['Class Label', 'Weight', 'Word'])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
