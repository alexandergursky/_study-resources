{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Messy Data\n",
    "  \n",
    "This chapter introduces you to the reality of messy and incomplete data. You will learn how to find where your data has missing values and explore multiple approaches on how to deal with them. You will also use string manipulation techniques to deal with unwanted characters in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do missing values exist?\n",
    "  \n",
    "In the first chapter, we looked at the different types of data one may find when analyzing data. In this lesson, we will explore the concept of messy and missing values, how to find them, and once identified, how to deal with them.\n",
    "  \n",
    "**How gaps in data occur**\n",
    "  \n",
    "While in an ideal world every dataset you come across would be perfectly complete and contain no gaps, unfortunately, this is rarely the case. Real world data often has noise or omissions. This can stem from many sources, for example: Data not being collected properly (paper surveys not being filled out fully). Collection and management errors (someone transcribing the data making a mistake). Data intentionally being omitted (people may want to skip the age box in an online form). Or gaps could be created due to transformations of the data (average of a field with missing data). This list is far from comprehensive.\n",
    "  \n",
    "**Why we care?**\n",
    "  \n",
    "You may wonder why are we discussing this? Does missing data even matter? Yes, it does, and it is extremely important to identify and deal with missing data. Many machine learning models cannot work with missing values, for example if you were performing linear regression, you would need a value for every row and column used in your dataset. Missing data may be indicative of a problem in your data pipeline. If data is consistently missing in a certain column, you should investigate as to why this is the case. Missing data may provide information in itself. For example, if the number of children of a person is missing they may have no children.\n",
    "  \n",
    "**Missing value discovery**\n",
    "  \n",
    "You can use the `.info()` method to have a preliminary look at how complete the dataset is. Right from the get go you can see that the `StackOverflowJobsRecommend`, `Gender`, and `RawSalary` columns are highly underpopulated and we should examine where these missing values occur. This list output is useful but becomes limited with larger datasets that have missing values scattered all over their features.\n",
    "  \n",
    "**Finding missing values**\n",
    "  \n",
    "To find where these missing values exist, you can use the `.isnull()` method as shown here. All cells where missing values exist are shown as `True`.\n",
    "  \n",
    "**Finding missing values**\n",
    "  \n",
    "You can also count the number of missing values in a specific column by chaining the `.isnull()` and `.sum()` methods as shown here.\n",
    "  \n",
    "**Finding non-missing values**\n",
    "  \n",
    "The inverse (or the non missing values) can also be found using the `.notnull()` method. Here, all missing values are shown as `False`. Note that you can call the `.isnull()` and `.notnull()` methods on both the DataFrame as a whole, and on each of it's individual columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How sparse is my data?\n",
    "  \n",
    "Most datasets contain missing values, often represented as `NaN` (Not a Number). If you are working with `Pandas` you can easily check how many missing values exist in each column.\n",
    "  \n",
    "Let's find out how many of the developers taking the survey chose to enter their age (found in the `Age` column of `so_survey_df`) and their gender (`Gender` column of `so_survey_df`).\n",
    "  \n",
    "1. Subset the DataFrame to only include the 'Age' and 'Gender' columns.\n",
    "2. Print the number of non-missing values in both columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SurveyDate</th>\n",
       "      <th>FormalEducation</th>\n",
       "      <th>ConvertedSalary</th>\n",
       "      <th>Hobby</th>\n",
       "      <th>Country</th>\n",
       "      <th>StackOverflowJobsRecommend</th>\n",
       "      <th>VersionControl</th>\n",
       "      <th>Age</th>\n",
       "      <th>Years Experience</th>\n",
       "      <th>Gender</th>\n",
       "      <th>RawSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/28/18 20:20</td>\n",
       "      <td>Bachelor's degree (BA. BS. B.Eng.. etc.)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Git</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/28/18 13:26</td>\n",
       "      <td>Bachelor's degree (BA. BS. B.Eng.. etc.)</td>\n",
       "      <td>70841.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sweeden</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Git;Subversion</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>Male</td>\n",
       "      <td>70,841.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/6/18 3:37</td>\n",
       "      <td>Bachelor's degree (BA. BS. B.Eng.. etc.)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Sweeden</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Git</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/9/18 1:06</td>\n",
       "      <td>Some college/university study without earning ...</td>\n",
       "      <td>21426.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sweeden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zip file back-ups</td>\n",
       "      <td>46</td>\n",
       "      <td>12</td>\n",
       "      <td>Male</td>\n",
       "      <td>21,426.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/12/18 22:41</td>\n",
       "      <td>Bachelor's degree (BA. BS. B.Eng.. etc.)</td>\n",
       "      <td>41671.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>UK</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Git</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>Male</td>\n",
       "      <td>£41,671.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SurveyDate                                    FormalEducation  \\\n",
       "0  2/28/18 20:20           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
       "1  6/28/18 13:26           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
       "2    6/6/18 3:37           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
       "3    5/9/18 1:06  Some college/university study without earning ...   \n",
       "4  4/12/18 22:41           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
       "\n",
       "   ConvertedSalary Hobby       Country  StackOverflowJobsRecommend  \\\n",
       "0              NaN   Yes  South Africa                         NaN   \n",
       "1          70841.0   Yes       Sweeden                         7.0   \n",
       "2              NaN    No       Sweeden                         8.0   \n",
       "3          21426.0   Yes       Sweeden                         NaN   \n",
       "4          41671.0   Yes            UK                         8.0   \n",
       "\n",
       "      VersionControl  Age  Years Experience Gender   RawSalary  \n",
       "0                Git   21                13   Male         NaN  \n",
       "1     Git;Subversion   38                 9   Male   70,841.00  \n",
       "2                Git   45                11    NaN         NaN  \n",
       "3  Zip file back-ups   46                12   Male   21,426.00  \n",
       "4                Git   39                 7   Male  £41,671.00  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so_survey_df = pd.read_csv('../_datasets/Combined_DS_v10.csv')\n",
    "so_survey_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age       999\n",
      "Gender    693\n",
      "dtype: int64\n",
      "Age         0\n",
      "Gender    306\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Subset the DataFrame\n",
    "sub_df = so_survey_df[['Age', 'Gender']]\n",
    "\n",
    "# Print the number of non-missing values, and the number of missing\n",
    "print(sub_df.notnull().sum())   # Not missing\n",
    "print(sub_df.isna().sum())      # Is missing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "  \n",
    "Based on the results, how many non-missing entries are there in the Gender column?  \n",
    "Possible answers  \n",
    "- [ ] 999\n",
    "- [x] 693\n",
    "  \n",
    "Correct, there are 693 non-missing entries in the Gender column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the missing values\n",
    "  \n",
    "While having a summary of how much of your data is missing can be useful, often you will need to find the exact locations of these missing values. Using the same subset of the StackOverflow data from the last exercise (`sub_df`), you will show how a value can be flagged as missing.\n",
    "  \n",
    "1. Print the first 10 entries of the DataFrame.\n",
    "2. Print the locations of the missing values in the first 10 rows.\n",
    "3. Print the locations of the non-missing values in the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender\n",
       "0   21    Male\n",
       "1   38    Male\n",
       "2   45     NaN\n",
       "3   46    Male\n",
       "4   39    Male\n",
       "5   39    Male\n",
       "6   34    Male\n",
       "7   24  Female\n",
       "8   23    Male\n",
       "9   36     NaN"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top 10 entries of the DataFrame\n",
    "sub_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender\n",
       "0  False   False\n",
       "1  False   False\n",
       "2  False    True\n",
       "3  False   False\n",
       "4  False   False\n",
       "5  False   False\n",
       "6  False   False\n",
       "7  False   False\n",
       "8  False   False\n",
       "9  False    True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the locations of the missing values\n",
    "sub_df.head(10).isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender\n",
       "0  True    True\n",
       "1  True    True\n",
       "2  True   False\n",
       "3  True    True\n",
       "4  True    True\n",
       "5  True    True\n",
       "6  True    True\n",
       "7  True    True\n",
       "8  True    True\n",
       "9  True   False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the locations of the non-missing values\n",
    "sub_df.head(10).notnull()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done, finding where the missing values exist can often be important."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing values (I)\n",
    "  \n",
    "Now that you can recognize why missing values occur and how to locate them, you need to know how they can be dealt with.\n",
    "  \n",
    "**Listwise deletion**\n",
    "  \n",
    "If you are confident that the missing values in your dataset are occurring at random, (in other words not being intentionally omitted) the most effective and statistically sound approach to dealing with them is called '*complete case analysis*' or *listwise deletion*. In this method, a record/observation is fully excluded from your model if any of its values are missing. Take for example the dataset shown here. Although most of the information is available in the first and third rows, because values in the `ConvertedSalary` column are missing, these rows will be dropped.\n",
    "  \n",
    "<img src='../_images/list-wise-deletion-example-dealing-with-missing-values.png' text='alt text' width='500'>\n",
    "  \n",
    "**Listwise deletion in Python**\n",
    "  \n",
    "To implement listwise deletion using pandas, you can use the `.dropna()` method, by setting the `how=` argument to 'any'. This will delete all rows with at least one missing value.\n",
    "  \n",
    "`# Drop all rows/observations with at least one missing value`  \n",
    "`df.dropna(how='any')`  \n",
    "  \n",
    "**Listwise deletion in Python**\n",
    "  \n",
    "On the other hand, if you want to delete rows with missing values in only a specific column, you can use the `subset=[]` argument. Pass a list of columns to this argument to specify which columns to consider when deleting rows.\n",
    "  \n",
    "`# Drop rows/observations with missing values in a defined list of columns`  \n",
    "`df.dropna(subset=['column1','column2', 'column3'])`  \n",
    "  \n",
    "**Issues with deletion**\n",
    "  \n",
    "While the preferable approach in situations where missing data occurs purely at random is listwise deletion, it does have its drawbacks. First, it deletes perfectly valid data points that share a row with a missing value. Second, if the missing values do not occur entirely at random it can negatively affect the model. Lastly, if you were to remove a feature instead of a row it can reduce the degrees of freedom of your model.\n",
    "  \n",
    "**Replacing with strings**\n",
    "  \n",
    "The most common way to deal with missing values is to simply fill these values using the `.fillna()` method. To use the `.fillna()` method on a specific column, you need to provide the value you want to replace the missing values with. In the case of categorical columns, it is common to replace missing values with strings like 'Other', 'Not Given' etc. To replace the missing values in-place, in other words to modify the original DataFrame, you need to set the `inplace=` argument to `True`.\n",
    "  \n",
    "`# Replace missing values in a specific column with a string`  \n",
    "`df['column'].fillna(value='absent value located here', inplace=True)`  \n",
    "  \n",
    "**Recording missing values**\n",
    "  \n",
    "In situations where you believe that the absence or presence of data is more important than the values themselves, you can create a new column that records the absence of data and then drop the original column. To do this, all you need to do is call the `.notnull()` method on a specific column. This will output a list of `True`/`False` values, thus recording the presence/absence of data. To drop columns from a DataFrame, you can use the `.drop()` method and specify a list of column names which you want to drop as the `columns=[]` argument.\n",
    "  \n",
    "`# Record True/False where the values are not missing and place into a new column`  \n",
    "`df['column2'] = df['column1'].notnull()`  \n",
    "  \n",
    "`# Drop a specific column`  \n",
    "`df.drop(columns=['column'])`  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listwise deletion\n",
    "  \n",
    "The simplest way to deal with missing values in your dataset when they are occurring entirely at random is to remove those rows, also called '*listwise deletion*'.\n",
    "  \n",
    "Depending on the use case, you will sometimes want to remove all missing values in your data while other times you may want to only remove a particular column if too many values are missing in that column.\n",
    "  \n",
    "1. Print the number of rows and columns in `so_survey_df`.\n",
    "2. Drop all rows with missing values in `so_survey_df`.\n",
    "3. Drop all columns with missing values in `so_survey_df`.\n",
    "4. Drop all rows in `so_survey_df` where 'Gender' is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 11)\n"
     ]
    }
   ],
   "source": [
    "# Print the number of rows and columns\n",
    "print(so_survey_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 11)\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame dropping all incomplete rows, no argument defined does this too\n",
    "no_missing_values_rows = so_survey_df.dropna(axis=0)\n",
    "\n",
    "# Print the shape of the new DataFrame\n",
    "print(no_missing_values_rows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 7)\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame dropping all columns with incomplete rows\n",
    "no_missing_values_cols = so_survey_df.dropna(axis=1)\n",
    "\n",
    "# Print the shape fo the new DataFrame\n",
    "print(no_missing_values_cols.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693, 11)\n"
     ]
    }
   ],
   "source": [
    "# Drop all rows where Gender is missing\n",
    "no_gender = so_survey_df.dropna(subset=['Gender'], axis=0)\n",
    "\n",
    "# Print the shape of the new DataFrame\n",
    "print(no_gender.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct, as you can see dropping all rows that contain any missing values may greatly reduce the size of your dataset. So you need to think carefully and consider several trade-offs when deleting missing values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing missing values with constants\n",
    "  \n",
    "While removing missing data entirely maybe a correct approach in many situations, this may result in a lot of information being omitted from your models.\n",
    "  \n",
    "You may find categorical columns where the missing value is a valid piece of information in itself, such as someone refusing to answer a question in a survey. In these cases, you can fill all missing values with a new category entirely, for example 'No response given'.\n",
    "  \n",
    "1. Print the count of occurrences of each category in `so_survey_df`'s `Gender` column.\n",
    "2. Replace all missing values in the `Gender` column with the string 'Not Given'. Make changes to the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male                                                                         632\n",
      "Female                                                                        53\n",
      "Female;Male                                                                    2\n",
      "Transgender                                                                    2\n",
      "Female;Male;Transgender;Non-binary. genderqueer. or gender non-conforming      1\n",
      "Male;Non-binary. genderqueer. or gender non-conforming                         1\n",
      "Non-binary. genderqueer. or gender non-conforming                              1\n",
      "Female;Transgender                                                             1\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the count of occurrence\n",
    "print(so_survey_df['Gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male                                                                         632\n",
      "Not Given                                                                    306\n",
      "Female                                                                        53\n",
      "Female;Male                                                                    2\n",
      "Transgender                                                                    2\n",
      "Female;Male;Transgender;Non-binary. genderqueer. or gender non-conforming      1\n",
      "Male;Non-binary. genderqueer. or gender non-conforming                         1\n",
      "Non-binary. genderqueer. or gender non-conforming                              1\n",
      "Female;Transgender                                                             1\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values\n",
    "so_survey_df['Gender'].fillna('Not Given', inplace=True)\n",
    "\n",
    "# Print the count of each value\n",
    "print(so_survey_df['Gender'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By filling in these missing values you can use the columns in your analyses."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill continuous missing values**\n",
    "  \n",
    "While listwise deletion is often the most statistically sound method of dealing with missing values in cases where you believe the gaps are at random, this will often not be feasible in real world use cases.\n",
    "  \n",
    "**Deleting missing values**\n",
    "  \n",
    "One of the most common issues with removing all rows with missing values is if you were building a predictive model. If you were to remove all cases that had missing values when training your model, you would quickly run into problems when you received missing values in your test set, where you do not have the option of just not predicting these rows.\n",
    "  \n",
    "**What else can you do?**\n",
    "  \n",
    "So what's the alternative? Replacing missing values. For categorical columns, as you saw in the last lesson you can either replace missing values with a string that flags missing values such as 'None', or you can use the most common occurring value. However, for numeric columns, you may want to replace missing values with a more suitable value. So what is a suitable value?\n",
    "  \n",
    "**Measures of central tendency**\n",
    "  \n",
    "In cases like this we often turn to the measures of central tendency, which are the central or typical value for a distribution. The most commonly used values are the mean and the median. One caveat that you must keep in mind when using these methods is that it can lead to biased estimates of the variances and covariances of the features. Similarly, the standard error and test statistics can be incorrectly estimated so if these metrics are needed they should be calculated before the missing values have been filled.\n",
    "  \n",
    "**Calculating the measures of central tendency**\n",
    "  \n",
    "You can calculate these measures directly from a `pandas` series by simply calling the required method on the series as shown here. Note that the missing values are excluded by default when calculating these statistics.\n",
    "  \n",
    "**Fill the missing values**\n",
    "  \n",
    "Then leveraging what you implemented in previous lesson, you can directly fill all missing values using the `.fillna()` method. Only this time you are filling missing values in the `ConvertedSalary` column with the mean of this column. Since you filled in the missing values with the mean, you may end up with too many decimal places. You can get rid of all the decimal values by changing the data type to integer using the `.astype()` method like so.\n",
    "  \n",
    "**Rounding values**\n",
    "  \n",
    "Or you can first round the mean before filling in the missing values as shown here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling continuous missing values\n",
    "  \n",
    "In the last lesson, you dealt with different methods of removing data missing values and filling in missing values with a fixed string. These approaches are valid in many cases, particularly when dealing with categorical columns but have limited use when working with continuous values. In these cases, it may be most valid to fill the missing values in the column with a value calculated from the entries present in the column.\n",
    "  \n",
    "1. Print the first five rows of the `StackOverflowJobsRecommend` column of `so_survey_df`.\n",
    "2. Replace the missing values in the `StackOverflowJobsRecommend` column with its mean. Make changes directly to the original DataFrame.\n",
    "3. Round the decimal values that you introduced in the `StackOverflowJobsRecommend` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    7.0\n",
       "2    8.0\n",
       "3    NaN\n",
       "4    8.0\n",
       "Name: StackOverflowJobsRecommend, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first five rows of StackOverflowJobsRecommend column\n",
    "so_survey_df['StackOverflowJobsRecommend'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7.0\n",
       "1    7.0\n",
       "2    8.0\n",
       "3    7.0\n",
       "4    8.0\n",
       "Name: StackOverflowJobsRecommend, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing values with the mean\n",
    "so_survey_df['StackOverflowJobsRecommend'].fillna(\n",
    "    so_survey_df['StackOverflowJobsRecommend'].mean(), inplace=True)\n",
    "\n",
    "# Round the StackOverflowJobsRecommend values\n",
    "so_survey_df['StackOverflowJobsRecommend'] = round(so_survey_df['StackOverflowJobsRecommend'])\n",
    "\n",
    "# Print the first five rows of StackOverflowJobsRecommend column\n",
    "so_survey_df['StackOverflowJobsRecommend'].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done, remember you should only round your values if you are certain it is applicable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing values in predictive models\n",
    "  \n",
    "When working with predictive models you will often have a separate train and test DataFrames. In these cases you want to ensure no information from your test set leaks into your train set(data-leakage). When filling missing values in data to be used in these situations how should you approach the two datasets?\n",
    "  \n",
    "Possible Answers\n",
    "  \n",
    "- [ ] Only fill the train set.\n",
    "  \n",
    "- [ ] Only fill the test set.\n",
    "  \n",
    "- [x] Apply the measures of central tendency (mean/median etc.) calculated on the train set to both the train and test sets.\n",
    "  \n",
    "- [ ] Apply the measures of central tendency (mean/median etc.) calculated on the test set to both the train and test sets.\n",
    "  \n",
    "- [ ] Apply the measures of central tendency (mean/median etc.) calculated on the train set to the train set, and the measures calculated on the test set, to the test set.\n",
    "  \n",
    "Correct, values calculated on the train test should be applied to both DataFrames."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with other data issues\n",
    "  \n",
    "Up to this point you have used multiple approaches to creating and updating features when missing values are present in the data, but data issues are of course not limited to just this. In some instances, you will come across features that need to be updated in some other way. Take for example the case of a column containing a monetary value. If this dataset has been imported from excel it may contain characters such as currency signs or commas that prevents pandas from reading it as numeric values.\n",
    "  \n",
    "**Bad characters**\n",
    "  \n",
    "For example, lets look at the data type of the `RawSalary` column. It's an object, although intuitively, you know that it should be numeric. So why is that?\n",
    "  \n",
    "<img src='../_images/bad-characters-in-a-column.png' text='alt text' width='500'>\n",
    "  \n",
    "**Bad characters**\n",
    "  \n",
    "Let's take a quick peek at the data. Numeric columns should not contain any non-numeric characters. So you need to remove these commas.\n",
    "  \n",
    "<img src='../_images/bad-characters-in-a-column1.png' text='alt text' width='500'>\n",
    "  \n",
    "**Dealing with bad characters**\n",
    "  \n",
    "Although you want the column to be a numeric column, it is of type object, which means you can use string methods to fix this column. In this case, we want to remove all occurrences of comma. We can easily achieve this by accessing the `str` accessor and using the `.replace()` method. The first argument is the string you want to replace, which is the comma, and the second argument is the string you want to replace it with, which here is an empty string, which simply means you want to remove all the commas. However, the data type of this column is still object. Now you can convert your column to the relevant type as shown here.\n",
    "  \n",
    "<img src='../_images/dealing-with-bad-characters-in-a-column.png' text='alt text' width='500'>\n",
    "  \n",
    "**Finding other stray characters**\n",
    "  \n",
    "But what if attempting to change the data type raises an error? This may indicate that there are additional stray characters which you didn't account for. Instead of manually searching for values with other stray characters you can use the `pd.to_numeric()` function from `pandas` along with the `errors=` argument. If you set the `errors=` argument to 'coerce', Pandas will convert the column to numeric, but all values that can't be converted to numeric will be changed to NaNs, that is missing values.\n",
    "  \n",
    "**Finding other stray characters**\n",
    "  \n",
    "You can now use the `.isna()` method like you did earlier to find out which values failed to parse. So it looks like we also have dollar signs. You can again use the `.replace()` method as before to remove the dollar signs.\n",
    "  \n",
    "<img src='../_images/dealing-with-bad-characters-in-a-column1.png' text='alt text' width='500'>\n",
    "  \n",
    "**Chaining methods**\n",
    "  \n",
    "Before you get going onto trying these for yourself, it will be useful to delve a little deeper into method chaining. If you are applying different methods or in fact the same method several times on a column, instead of assigning the result back to the column after each iteration, you can simply chain the methods, that is, call one method after the other to obtain the desired result. For example, cleaning up characters, changing the data type, normalizing the values etc. can all be achieved by simply calling the methods one after the other as seen here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with stray characters (I)\n",
    "  \n",
    "In this exercise, you will work with the `RawSalary` column of `so_survey_df` which contains the wages of the respondents along with the currency symbols and commas, such as $42,000. When importing data from Microsoft Excel, more often that not you will come across data in this form.\n",
    "  \n",
    "1. Remove the commas (,) from the `RawSalary` column.\n",
    "2. Remove the dollar ($) signs from the `RawSalary` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the commas in the column\n",
    "so_survey_df['RawSalary'] = so_survey_df['RawSalary'].str.replace(',', '', regex=False)\n",
    "\n",
    "# Remove the dollar signs in the column\n",
    "so_survey_df['RawSalary'] = so_survey_df['RawSalary'].str.replace('$', '', regex=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
    "  so_survey_df['RawSalary'] = so_survey_df['RawSalary'].str.replace('$', '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Replacing/removing specific characters is a very useful skill."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with stray characters (II)\n",
    "  \n",
    "In the last exercise, you could tell quickly based off of the `df.head()` call which characters were causing an issue. In many cases this will not be so apparent. There will often be values deep within a column that are preventing you from casting a column as a numeric type so that it can be used in a model or further feature engineering.\n",
    "  \n",
    "One approach to finding these values is to force the column to the data type desired using `pd.to_numeric()`, coercing any values causing issues to NaN, Then filtering the DataFrame by just the rows containing the NaN values.\n",
    "  \n",
    "Try to cast the `RawSalary` column as a float and it will fail as an additional character can now be found in it. Find the character and remove it so the column can be cast as a float.\n",
    "  \n",
    "1. Attempt to convert the RawSalary column of `so_survey_df` to numeric values coercing all failures into null values.\n",
    "2. Find the indexes of the rows containing NaNs.\n",
    "3. Print the rows in `RawSalary` based on these indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      NaN\n",
      "2      NaN\n",
      "6      NaN\n",
      "8      NaN\n",
      "11     NaN\n",
      "      ... \n",
      "989    NaN\n",
      "990    NaN\n",
      "992    NaN\n",
      "994    NaN\n",
      "997    NaN\n",
      "Name: RawSalary, Length: 334, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Attempt to convert the column to numeric values\n",
    "numeric_vals = pd.to_numeric(so_survey_df['RawSalary'], errors='coerce')\n",
    "\n",
    "# find the indexes of missing values\n",
    "idx = so_survey_df['RawSalary'].isna()\n",
    "\n",
    "# Print the relevant raws\n",
    "print(so_survey_df['RawSalary'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1        70841.0\n",
       "2            NaN\n",
       "3        21426.0\n",
       "4        41671.0\n",
       "         ...    \n",
       "994          NaN\n",
       "995      58746.0\n",
       "996      55000.0\n",
       "997          NaN\n",
       "998    1000000.0\n",
       "Name: RawSalary, Length: 999, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the offending characters\n",
    "so_survey_df['RawSalary'] = so_survey_df['RawSalary'].str.replace('£', '', regex=False)\n",
    "\n",
    "# Convert the column to float\n",
    "so_survey_df['RawSalary'] = so_survey_df['RawSalary'].astype(float)\n",
    "\n",
    "# Print the column\n",
    "so_survey_df['RawSalary']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done! Remember that even after removing all the relevant characters, you still need to change the type of the column to numeric if you want to plot these continuous values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method chaining\n",
    "  \n",
    "When applying multiple operations on the same column (like in the previous exercises), you made the changes in several steps, assigning the results back in each step. However, when applying multiple successive operations on the same column, you can \"chain\" these operations together for clarity and ease of management. This can be achieved by calling multiple methods sequentially:\n",
    "  \n",
    "```\n",
    "# Method chaining\n",
    "df['column'] = df['column'].method1().method2().method3()\n",
    "\n",
    "# Same as \n",
    "df['column'] = df['column'].method1()\n",
    "df['column'] = df['column'].method2()\n",
    "df['column'] = df['column'].method3()\n",
    "```\n",
    "  \n",
    "In this exercise you will repeat the steps you performed in the last two exercises, but do so using method chaining.\n",
    "  \n",
    "1. Remove the commas (,) from the `RawSalary` column of `so_survey_df`.\n",
    "2. Remove the dollar ($) signs from the `RawSalary` column.\n",
    "3. Remove the pound (£) signs from the `RawSalary` column.\n",
    "4. Convert the `RawSalary` column to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            NaN\n",
      "1        70841.0\n",
      "2            NaN\n",
      "3        21426.0\n",
      "4        41671.0\n",
      "         ...    \n",
      "994          NaN\n",
      "995      58746.0\n",
      "996      55000.0\n",
      "997          NaN\n",
      "998    1000000.0\n",
      "Name: RawSalary, Length: 999, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "so_survey_df = pd.read_csv('../_datasets/Combined_DS_v10.csv')\n",
    "\n",
    "# Use method chaining\n",
    "so_survey_df['RawSalary'] = so_survey_df['RawSalary']\\\n",
    "                            .str.replace(',', '', regex=False)\\\n",
    "                            .str.replace('$', '', regex=False)\\\n",
    "                            .str.replace('£', '', regex=False)\\\n",
    "                            .astype(float)\n",
    "\n",
    "# Print the RawSalary column\n",
    "print(so_survey_df['RawSalary'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! Custom functions can be also used when method chaining using the .apply() method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
